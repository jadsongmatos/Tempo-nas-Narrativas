{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B\", legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Please ensure you have a compatible GPU and drivers installed.\")\n",
    "else:\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ./Llama-3.2-1b-Gather/ and are newly initialized: ['model.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList()\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Recarrega o modelo salvo\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './Llama-3.2-1b-Gather/').to('cpu')\n",
    "\n",
    "# Verifica a estrutura do modelo recarregado\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(input_text):\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to('cpu')\n",
    "        embedding = model.model.embed_tokens(input_ids)  # [1,2048] até [1024,2048]\n",
    "        embedding = embedding.cpu()  # Move para CPU\n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SequenceDataset_val(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # start_time = time.time()\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "        sequence1 = text_to_embedding(row['content1'])\n",
    "        sequence2 = text_to_embedding(row['content2'])\n",
    "\n",
    "        # Use the transformed target\n",
    "        target = torch.tensor(row['target_transformed'], dtype=torch.float32)\n",
    "\n",
    "        # Convert sequences to tensors (no need to reconvert embedding)\n",
    "        #sequence1 = sequence1.float()\n",
    "        #sequence2 = sequence2.float()\n",
    "\n",
    "        # end_time = time.time()\n",
    "        # if idx % 1000 == 0:\n",
    "        #    logger.info(f\"Processing sample {idx}/{len(self.df)} - Time: {end_time - start_time:.4f}s\")\n",
    "\n",
    "        return sequence1, sequence2, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Caminhos para os bancos de dados\n",
    "db1_path = 'fineweb.duckdb'  # Substitua pelo caminho do seu primeiro banco de dados\n",
    "db2_path = 'books.duckdb'  # Substitua pelo caminho do seu segundo banco de dados\n",
    "\n",
    "# Alias para o segundo banco de dados\n",
    "alias_db2 = 'db2_alias'\n",
    "\n",
    "# Conectar ao banco de dados principal\n",
    "conn = duckdb.connect(database=db1_path, read_only=False)\n",
    "\n",
    "# Anexar o segundo banco de dados\n",
    "conn.execute(f\"ATTACH DATABASE '{db2_path}' AS {alias_db2}\")\n",
    "\n",
    "# Verificar esquemas (opcional, mas recomendado)\n",
    "schema_main = conn.execute(\"DESCRIBE dataset\").fetchdf()\n",
    "schema_db2 = conn.execute(f\"DESCRIBE {alias_db2}.dataset\").fetchdf()\n",
    "\n",
    "if not schema_main.equals(schema_db2):\n",
    "\traise Exception(\"Os esquemas das tabelas 'dataset' nos dois bancos de dados não são compatíveis.\")\n",
    "\n",
    "# Subamostragem\n",
    "def subamostrar_bin(df, bin_categoria, tamanho):\n",
    "\treturn df[df['bin'] == bin_categoria].sample(n=tamanho, random_state=42)\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "\tdef __init__(self):\n",
    "\t\tdf_training = conn.execute(f\"\"\"\n",
    "\t\t-- Materialize o combined_dataset primeiro\n",
    "\t\tCREATE TEMPORARY TABLE temp_combined_dataset AS\n",
    "\t\tSELECT * FROM dataset\n",
    "\t\tUNION ALL\n",
    "\t\tSELECT * FROM {alias_db2}.dataset;\n",
    "\n",
    "\t\t-- Em seguida, use a tabela temporária nas amostragens\n",
    "\t\tWITH sampled_a AS (\n",
    "\t\t\tSELECT id, indice, content, name\n",
    "\t\t\tFROM (\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tid,\n",
    "\t\t\t\t\tindice,\n",
    "\t\t\t\t\tcontent,\n",
    "\t\t\t\t\tname,\n",
    "\t\t\t\t\tROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "\t\t\t\t\tCOUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "\t\t\t\tFROM temp_combined_dataset\n",
    "\t\t\t) sub\n",
    "\t\t\tWHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    "\t\t),\n",
    "\t\tsampled_b AS (\n",
    "\t\t\tSELECT id, indice, content, name\n",
    "\t\t\tFROM (\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tid,\n",
    "\t\t\t\t\tindice,\n",
    "\t\t\t\t\tcontent,\n",
    "\t\t\t\t\tname,\n",
    "\t\t\t\t\tROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "\t\t\t\t\tCOUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "\t\t\t\tFROM temp_combined_dataset\n",
    "\t\t\t) sub\n",
    "\t\t\tWHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    "\t\t)\n",
    "\t\tSELECT\n",
    "\t\t\ta.name AS name,\n",
    "\t\t\ta.content AS content1,\n",
    "\t\t\tb.content AS content2,\n",
    "\t\t\tSIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed\n",
    "\t\tFROM sampled_a a\n",
    "\t\tJOIN sampled_b b\n",
    "\t\t\tON a.name = b.name\n",
    "\t\t\t-- AND a.id != b.id\n",
    "\t\tORDER BY RANDOM()\n",
    "\t\tLIMIT 10000;\n",
    "\t\t\"\"\").df()\n",
    "\n",
    "\t\t# Binarização\n",
    "\t\tnum_bins = 10\n",
    "\t\tdf_training['bin'] = pd.cut(df_training['target_transformed'], bins=num_bins)\n",
    "\n",
    "\t\t# Frequência por bin\n",
    "\t\tfrequencia = df_training['bin'].value_counts().sort_index()\n",
    "\n",
    "\t\t# Tamanho mínimo de amostra por bin\n",
    "\t\tmin_freq = frequencia.min()\n",
    "\n",
    "\t\tdf_uniforme = pd.concat([\n",
    "\t\t\tsubamostrar_bin(df_training, bin_cat, min_freq) \n",
    "\t\t\tfor bin_cat in frequencia.index\n",
    "\t\t])\n",
    "\n",
    "\t\tdf_uniforme = df_uniforme.reset_index(drop=True)\n",
    "\t\tdf_uniforme = df_uniforme.drop('bin', axis=1)\n",
    "\t\tself.df = df_uniforme.reset_index(drop=True)\n",
    "\t\t\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn 20000\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tif idx % len(self.df) == 0:\n",
    "\t\t\tdf_training = conn.execute(f\"\"\"\n",
    "\t\t\t-- Materialize o combined_dataset primeiro\n",
    "\t\t\tCREATE TEMPORARY TABLE temp_combined_dataset AS\n",
    "\t\t\tSELECT * FROM dataset\n",
    "\t\t\tUNION ALL\n",
    "\t\t\tSELECT * FROM {alias_db2}.dataset;\n",
    "\n",
    "\t\t\t-- Em seguida, use a tabela temporária nas amostragens\n",
    "\t\t\tWITH sampled_a AS (\n",
    "\t\t\t\tSELECT id, indice, content, name\n",
    "\t\t\t\tFROM (\n",
    "\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\tid,\n",
    "\t\t\t\t\t\tindice,\n",
    "\t\t\t\t\t\tcontent,\n",
    "\t\t\t\t\t\tname,\n",
    "\t\t\t\t\t\tROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "\t\t\t\t\t\tCOUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "\t\t\t\t\tFROM temp_combined_dataset\n",
    "\t\t\t\t) sub\n",
    "\t\t\t\tWHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    "\t\t\t),\n",
    "\t\t\tsampled_b AS (\n",
    "\t\t\t\tSELECT id, indice, content, name\n",
    "\t\t\t\tFROM (\n",
    "\t\t\t\t\tSELECT\n",
    "\t\t\t\t\t\tid,\n",
    "\t\t\t\t\t\tindice,\n",
    "\t\t\t\t\t\tcontent,\n",
    "\t\t\t\t\t\tname,\n",
    "\t\t\t\t\t\tROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "\t\t\t\t\t\tCOUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "\t\t\t\t\tFROM temp_combined_dataset\n",
    "\t\t\t\t) sub\n",
    "\t\t\t\tWHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    "\t\t\t)\n",
    "\t\t\tSELECT\n",
    "\t\t\t\ta.name AS name,\n",
    "\t\t\t\ta.content AS content1,\n",
    "\t\t\t\tb.content AS content2,\n",
    "\t\t\t\tSIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed\n",
    "\t\t\tFROM sampled_a a\n",
    "\t\t\tJOIN sampled_b b\n",
    "\t\t\t\tON a.name = b.name\n",
    "\t\t\t\t-- AND a.id != b.id\n",
    "\t\t\tORDER BY RANDOM()\n",
    "\t\t\tLIMIT 10000;\n",
    "\t\t\t\"\"\").df()\n",
    "\n",
    "\t\t\t# Binarização\n",
    "\t\t\tnum_bins = 10\n",
    "\t\t\tdf_training['bin'] = pd.cut(df_training['target_transformed'], bins=num_bins)\n",
    "\n",
    "\t\t\t# Frequência por bin\n",
    "\t\t\tfrequencia = df_training['bin'].value_counts().sort_index()\n",
    "\n",
    "\t\t\t# Tamanho mínimo de amostra por bin\n",
    "\t\t\tmin_freq = frequencia.min()\n",
    "\n",
    "\t\t\tdf_uniforme = pd.concat([\n",
    "\t\t\t\tsubamostrar_bin(df_training, bin_cat, min_freq) \n",
    "\t\t\t\tfor bin_cat in frequencia.index\n",
    "\t\t\t])\n",
    "\n",
    "\t\t\tdf_uniforme = df_uniforme.reset_index(drop=True)\n",
    "\t\t\tself.df = df_uniforme.drop('bin', axis=1)\n",
    "\n",
    "\t\tprint(\"idx\",idx)\n",
    "\t\trow = self.df.iloc[idx%len(self.df)]\n",
    "\t\tsequence1 = text_to_embedding(row['content1'])\n",
    "\t\tsequence2 = text_to_embedding(row['content2'])\n",
    "\n",
    "\t\t# Use the transformed target\n",
    "\t\ttarget = torch.tensor(row['target_transformed'], dtype=torch.float32)\n",
    "\n",
    "\t\treturn sequence1, sequence2, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Caminhos para os bancos de dados\n",
    "db1_path = 'fineweb.duckdb'  # Substitua pelo caminho do seu primeiro banco de dados\n",
    "db2_path = 'books.duckdb'  # Substitua pelo caminho do seu segundo banco de dados\n",
    "\n",
    "# Alias para o segundo banco de dados\n",
    "alias_db2 = 'db2_alias'\n",
    "\n",
    "def subamostrar_bin(df, bin_categoria, tamanho):\n",
    "    return df[df['bin'] == bin_categoria].sample(n=tamanho, random_state=42)\n",
    "\n",
    "class InfiniteSequenceDataset(IterableDataset):\n",
    "    def __init__(self, db1_path, db2_path, alias_db2, batch_size=10000, num_bins=10):\n",
    "        super(InfiniteSequenceDataset, self).__init__()\n",
    "        self.db1_path = db1_path\n",
    "        self.db2_path = db2_path\n",
    "        self.alias_db2 = alias_db2\n",
    "        self.batch_size = batch_size\n",
    "        self.num_bins = num_bins\n",
    "\n",
    "    def _fetch_data(self, conn):\n",
    "        query = f\"\"\"\n",
    "        -- Materialize the combined_dataset first\n",
    "        CREATE TEMPORARY TABLE temp_combined_dataset AS\n",
    "        SELECT * FROM dataset\n",
    "        UNION ALL\n",
    "        SELECT * FROM {self.alias_db2}.dataset;\n",
    "\n",
    "        -- Use the temporary table for sampling\n",
    "        WITH sampled_a AS (\n",
    "            SELECT id, indice, content, name\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    id,\n",
    "                    indice,\n",
    "                    content,\n",
    "                    name,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "                    COUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "                FROM temp_combined_dataset\n",
    "            ) sub\n",
    "            WHERE rn <= CEIL(0.10 * total_count)  -- Adjust the rate as needed\n",
    "        ),\n",
    "        sampled_b AS (\n",
    "            SELECT id, indice, content, name\n",
    "            FROM (\n",
    "                SELECT\n",
    "                    id,\n",
    "                    indice,\n",
    "                    content,\n",
    "                    name,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "                    COUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "                FROM temp_combined_dataset\n",
    "            ) sub\n",
    "            WHERE rn <= CEIL(0.10 * total_count)  -- Adjust the rate as needed\n",
    "        )\n",
    "        SELECT\n",
    "            a.name AS name,\n",
    "            a.content AS content1,\n",
    "            b.content AS content2,\n",
    "            SIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed\n",
    "        FROM sampled_a a\n",
    "        JOIN sampled_b b\n",
    "            ON a.name = b.name\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT {self.batch_size};\n",
    "        \"\"\"\n",
    "        df = conn.execute(query).df()\n",
    "\n",
    "        # Binarização\n",
    "        df['bin'] = pd.cut(df['target_transformed'], bins=self.num_bins)\n",
    "\n",
    "        # Frequência por bin\n",
    "        frequencia = df['bin'].value_counts().sort_index()\n",
    "\n",
    "        # Tamanho mínimo de amostra por bin\n",
    "        min_freq = frequencia.min()\n",
    "\n",
    "        df_uniforme = pd.concat([\n",
    "            subamostrar_bin(df, bin_cat, min_freq) \n",
    "            for bin_cat in frequencia.index\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "        df_uniforme = df_uniforme.drop('bin', axis=1)\n",
    "        return df_uniforme\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Each worker will have its own connection\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:\n",
    "            # Single worker\n",
    "            conn = duckdb.connect(database=self.db1_path, read_only=False)\n",
    "            conn.execute(f\"ATTACH DATABASE '{self.db2_path}' AS {self.alias_db2}\")\n",
    "            while True:\n",
    "                df = self._fetch_data(conn)\n",
    "                for _, row in df.iterrows():\n",
    "                    sequence1 = text_to_embedding(row['content1'])\n",
    "                    sequence2 = text_to_embedding(row['content2'])\n",
    "                    target = torch.tensor(row['target_transformed'], dtype=torch.float32)\n",
    "                    yield sequence1, sequence2, target\n",
    "        else:\n",
    "            # Multiple workers\n",
    "            conn = duckdb.connect(database=self.db1_path, read_only=False)\n",
    "            conn.execute(f\"ATTACH DATABASE '{self.db2_path}' AS {self.alias_db2}\")\n",
    "            while True:\n",
    "                df = self._fetch_data(conn)\n",
    "                for _, row in df.iterrows():\n",
    "                    sequence1 = text_to_embedding(row['content1'])\n",
    "                    sequence2 = text_to_embedding(row['content2'])\n",
    "                    target = torch.tensor(row['target_transformed'], dtype=torch.float32)\n",
    "                    yield sequence1, sequence2, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def signed_log_transform(y):\n",
    "    return np.sign(y) * np.log1p(np.abs(y))\n",
    "\n",
    "def inverse_signed_log_transform(y_transformed):\n",
    "    return np.sign(y_transformed) * (np.expm1(np.abs(y_transformed)))\n",
    "\n",
    "def dissimilaridade(S):\n",
    "\tepsilon = 0\n",
    "\tif S == 0:\n",
    "\t\tmax_x = np.log(np.finfo(np.float32).max)\n",
    "\t\tepsilon = (1/(max_x-1))\n",
    "        \n",
    "\treturn (1 - (S+epsilon)) / (S+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Unique file handle conflict: Database \"db2_alias\" is already attached with path \"books.duckdb\", ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBinderException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m conn \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect(database\u001b[38;5;241m=\u001b[39mdb1_path, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Anexar o segundo banco de dados\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m conn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mATTACH DATABASE \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb2_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias_db2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Verificar esquemas (opcional, mas recomendado)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m schema_main \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDESCRIBE dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mfetchdf()\n",
      "\u001b[0;31mBinderException\u001b[0m: Binder Error: Unique file handle conflict: Database \"db2_alias\" is already attached with path \"books.duckdb\", "
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Caminhos para os bancos de dados\n",
    "db1_path = 'fineweb.duckdb'  # Substitua pelo caminho do seu primeiro banco de dados\n",
    "db2_path = 'books.duckdb'  # Substitua pelo caminho do seu segundo banco de dados\n",
    "\n",
    "# Alias para o segundo banco de dados\n",
    "alias_db2 = 'db2_alias'\n",
    "\n",
    "# Conectar ao banco de dados principal\n",
    "conn = duckdb.connect(database=db1_path, read_only=False)\n",
    "\n",
    "# Anexar o segundo banco de dados\n",
    "conn.execute(f\"ATTACH DATABASE '{db2_path}' AS {alias_db2}\")\n",
    "\n",
    "# Verificar esquemas (opcional, mas recomendado)\n",
    "schema_main = conn.execute(\"DESCRIBE dataset\").fetchdf()\n",
    "schema_db2 = conn.execute(f\"DESCRIBE {alias_db2}.dataset\").fetchdf()\n",
    "\n",
    "if not schema_main.equals(schema_db2):\n",
    "\traise Exception(\"Os esquemas das tabelas 'dataset' nos dois bancos de dados não são compatíveis.\")\n",
    "\n",
    "# Executar a consulta modificada\n",
    "df_training = conn.execute(f\"\"\"\n",
    "-- Materialize o combined_dataset primeiro\n",
    "CREATE TEMPORARY TABLE temp_combined_dataset AS\n",
    "SELECT * FROM dataset\n",
    "UNION ALL\n",
    "SELECT * FROM {alias_db2}.dataset;\n",
    "\n",
    "-- Em seguida, use a tabela temporária nas amostragens\n",
    "WITH sampled_a AS (\n",
    "    SELECT id, indice, content, name\n",
    "    FROM (\n",
    "        SELECT\n",
    "            id,\n",
    "            indice,\n",
    "            content,\n",
    "            name,\n",
    "            ROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "            COUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "        FROM temp_combined_dataset\n",
    "    ) sub\n",
    "    WHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    "),\n",
    "sampled_b AS (\n",
    "    SELECT id, indice, content, name\n",
    "    FROM (\n",
    "        SELECT\n",
    "            id,\n",
    "            indice,\n",
    "            content,\n",
    "            name,\n",
    "            ROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn,\n",
    "            COUNT(*) OVER (PARTITION BY name) AS total_count\n",
    "        FROM temp_combined_dataset\n",
    "    ) sub\n",
    "    WHERE rn <= CEIL(0.10 * total_count)  -- Ajuste a taxa conforme necessário\n",
    ")\n",
    "SELECT\n",
    "    a.name AS name,\n",
    "    a.content AS content1,\n",
    "    b.content AS content2,\n",
    "    SIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed\n",
    "FROM sampled_a a\n",
    "JOIN sampled_b b\n",
    "    ON a.name = b.name\n",
    "    -- AND a.id != b.id\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 10000;\n",
    "\"\"\").df()\n",
    "\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0ee3db3fbe45faa3a0aa0ffb6e2889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "      <th>indice_diff</th>\n",
       "      <th>target_transformed</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://m.fairfieldcitizenonline.com/news/artic...</td>\n",
       "      <td>calls that the authority receives</td>\n",
       "      <td>and 40,200 for a</td>\n",
       "      <td>3115</td>\n",
       "      <td>8.044305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.automart.co.za/cars/ford-ecosport-...</td>\n",
       "      <td>IMMACULATE CONDITION! SPACIOUS YET COMPACT SUV...</td>\n",
       "      <td>Glass,AM/FM Radio,Compact Disc</td>\n",
       "      <td>287</td>\n",
       "      <td>-5.662960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.mediabistro.com/articles/print.asp?...</td>\n",
       "      <td>use only. To order presentation-ready</td>\n",
       "      <td>Or, I Know Why the Winged Whale Sings and Lamb...</td>\n",
       "      <td>448</td>\n",
       "      <td>-6.107023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://p-engineers.de/mensa-girl-with-regards...</td>\n",
       "      <td>about every topic you talk about. This is very...</td>\n",
       "      <td>There are several factors that can generate a ...</td>\n",
       "      <td>1243</td>\n",
       "      <td>7.126087</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.lifehealthpro.com/2013/01/22/exchan...</td>\n",
       "      <td>provide help for individuals who seek face- to...</td>\n",
       "      <td>it expected hearing comments from members of t...</td>\n",
       "      <td>1884</td>\n",
       "      <td>7.541683</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>http://dictionary.reference.com/browse/freak%2...</td>\n",
       "      <td>frician \"to dance\" (not</td>\n",
       "      <td>(not recorded in M.E.,</td>\n",
       "      <td>19</td>\n",
       "      <td>-2.995732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>https://janebadgerbooks.co.uk/product/the-barn...</td>\n",
       "      <td>after they find a horse</td>\n",
       "      <td>get over the rivalry with the other troupe. Th...</td>\n",
       "      <td>41</td>\n",
       "      <td>-3.737670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>https://meaningfulmama.com/how-to-remove-the-v...</td>\n",
       "      <td>it's only happened a few times, but that is en...</td>\n",
       "      <td>worst feeling as a mom?</td>\n",
       "      <td>3004</td>\n",
       "      <td>8.008033</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>http://hra-news3.info/what-to-bring-for-thanks...</td>\n",
       "      <td>bust through the swinging doors.Flowers growin...</td>\n",
       "      <td>whos on her own. On</td>\n",
       "      <td>164</td>\n",
       "      <td>5.105945</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>https://ymlp338.net/internet-digital-interacti...</td>\n",
       "      <td>solely to two or three</td>\n",
       "      <td>Technology is strongest when it</td>\n",
       "      <td>1412</td>\n",
       "      <td>-7.253470</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "0      http://m.fairfieldcitizenonline.com/news/artic...   \n",
       "1      https://www.automart.co.za/cars/ford-ecosport-...   \n",
       "2      http://www.mediabistro.com/articles/print.asp?...   \n",
       "3      https://p-engineers.de/mensa-girl-with-regards...   \n",
       "4      http://www.lifehealthpro.com/2013/01/22/exchan...   \n",
       "...                                                  ...   \n",
       "19995  http://dictionary.reference.com/browse/freak%2...   \n",
       "19996  https://janebadgerbooks.co.uk/product/the-barn...   \n",
       "19997  https://meaningfulmama.com/how-to-remove-the-v...   \n",
       "19998  http://hra-news3.info/what-to-bring-for-thanks...   \n",
       "19999  https://ymlp338.net/internet-digital-interacti...   \n",
       "\n",
       "                                                content1  \\\n",
       "0                      calls that the authority receives   \n",
       "1      IMMACULATE CONDITION! SPACIOUS YET COMPACT SUV...   \n",
       "2                  use only. To order presentation-ready   \n",
       "3      about every topic you talk about. This is very...   \n",
       "4      provide help for individuals who seek face- to...   \n",
       "...                                                  ...   \n",
       "19995                            frician \"to dance\" (not   \n",
       "19996                            after they find a horse   \n",
       "19997  it's only happened a few times, but that is en...   \n",
       "19998  bust through the swinging doors.Flowers growin...   \n",
       "19999                             solely to two or three   \n",
       "\n",
       "                                                content2  indice_diff  \\\n",
       "0                                       and 40,200 for a         3115   \n",
       "1                         Glass,AM/FM Radio,Compact Disc          287   \n",
       "2      Or, I Know Why the Winged Whale Sings and Lamb...          448   \n",
       "3      There are several factors that can generate a ...         1243   \n",
       "4      it expected hearing comments from members of t...         1884   \n",
       "...                                                  ...          ...   \n",
       "19995                             (not recorded in M.E.,           19   \n",
       "19996  get over the rivalry with the other troupe. Th...           41   \n",
       "19997                            worst feeling as a mom?         3004   \n",
       "19998                                whos on her own. On          164   \n",
       "19999                    Technology is strongest when it         1412   \n",
       "\n",
       "       target_transformed  bin  \n",
       "0                8.044305   10  \n",
       "1               -5.662960    4  \n",
       "2               -6.107023    5  \n",
       "3                7.126087    8  \n",
       "4                7.541683    9  \n",
       "...                   ...  ...  \n",
       "19995           -2.995732    1  \n",
       "19996           -3.737670    1  \n",
       "19997            8.008033   10  \n",
       "19998            5.105945    3  \n",
       "19999           -7.253470    9  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Caminhos para os bancos de dados\n",
    "db1_path = 'fineweb.duckdb'  # Substitua pelo caminho do seu primeiro banco de dados\n",
    "db2_path = 'books.duckdb'  # Substitua pelo caminho do seu segundo banco de dados\n",
    "\n",
    "# Alias para o segundo banco de dados\n",
    "alias_db2 = 'db2_alias'\n",
    "\n",
    "# Conectar ao banco de dados principal\n",
    "conn = duckdb.connect(database=db1_path, read_only=False)\n",
    "\n",
    "# Anexar o segundo banco de dados\n",
    "conn.execute(f\"ATTACH DATABASE '{db2_path}' AS {alias_db2}\")\n",
    "\n",
    "# Verificar esquemas (opcional, mas recomendado)\n",
    "schema_main = conn.execute(\"DESCRIBE dataset\").fetchdf()\n",
    "schema_db2 = conn.execute(f\"DESCRIBE {alias_db2}.dataset\").fetchdf()\n",
    "\n",
    "if not schema_main.equals(schema_db2):\n",
    "\traise Exception(\"Os esquemas das tabelas 'dataset' nos dois bancos de dados não são compatíveis.\")\n",
    "\n",
    "# Executar a consulta modificada\n",
    "df_training = conn.execute(f\"\"\"\n",
    "WITH temp_combined_dataset AS (\n",
    "    SELECT * FROM dataset\n",
    "    UNION ALL\n",
    "    SELECT * FROM {alias_db2}.dataset\n",
    "),\n",
    "limited_sample AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        ROW_NUMBER() OVER (PARTITION BY name ORDER BY RANDOM()) AS rn\n",
    "    FROM temp_combined_dataset\n",
    "    WHERE RANDOM() < 0.5  -- Adjust the initial sampling rate as needed\n",
    "),\n",
    "sampled_data AS (\n",
    "    SELECT *\n",
    "    FROM limited_sample\n",
    "    WHERE rn <= 10  -- Limit to 10 rows per 'name' (adjust as needed)\n",
    "),\n",
    "paired_data AS (\n",
    "    SELECT\n",
    "        a.name,\n",
    "        a.content AS content1,\n",
    "        b.content AS content2,\n",
    "        ABS(a.indice - b.indice) AS indice_diff,\n",
    "        SIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed\n",
    "    FROM sampled_data a\n",
    "    JOIN sampled_data b\n",
    "        ON a.name = b.name \n",
    "\t\t-- AND a.id < b.id  -- Avoid duplicates and self-pairs\n",
    "),\n",
    "binned_pairs AS (\n",
    "    SELECT *,\n",
    "        NTILE(10) OVER (ORDER BY indice_diff) AS bin\n",
    "    FROM paired_data\n",
    "),\n",
    "final_sample AS (\n",
    "    SELECT *\n",
    "    FROM binned_pairs\n",
    "    WHERE RANDOM() < 0.5  -- Adjust per-bin sampling rate as needed\n",
    ")\n",
    "SELECT *\n",
    "FROM final_sample\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 20000;\n",
    "\"\"\").df()\n",
    "\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_training['target_transformed'], bins=50, alpha=0.5, label='target_transformed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Binarização\n",
    "num_bins = 10\n",
    "df_training['bin'] = pd.cut(df_training['target_transformed'], bins=num_bins)\n",
    "\n",
    "# Frequência por bin\n",
    "frequencia = df_training['bin'].value_counts().sort_index()\n",
    "\n",
    "# Tamanho mínimo de amostra por bin\n",
    "min_freq = frequencia.min()\n",
    "# Subamostragem\n",
    "def subamostrar_bin(df, bin_categoria, tamanho):\n",
    "    return df[df['bin'] == bin_categoria].sample(n=tamanho, random_state=42)\n",
    "\n",
    "df_uniforme = pd.concat([\n",
    "    subamostrar_bin(df_training, bin_cat, min_freq) \n",
    "    for bin_cat in frequencia.index\n",
    "])\n",
    "\n",
    "df_uniforme = df_uniforme.reset_index(drop=True)\n",
    "df_uniforme = df_uniforme.drop('bin', axis=1)\n",
    "\n",
    "plt.hist(df_uniforme['target_transformed'], bins=50, alpha=0.5, label='target_transformed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_transformed</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A tempestade durou várias horas durante a noite.</td>\n",
       "      <td>Pela manhã, muitas ruas estavam alagadas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ele estudou intensamente para o exame.</td>\n",
       "      <td>Conseguiu uma nota alta na prova.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A fábrica reduziu a emissão de poluentes.</td>\n",
       "      <td>A qualidade do ar na cidade melhorou.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Maria começou a praticar exercícios regularmente.</td>\n",
       "      <td>Ela perdeu peso e aumentou sua energia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O motor do carro parou de funcionar.</td>\n",
       "      <td>Ele teve que chamar o guincho para levar o car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1</td>\n",
       "      <td>Isso resultou na redução significativa das emi...</td>\n",
       "      <td>Após anos de pesquisa e desenvolvimento, a equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-1</td>\n",
       "      <td>Ela sentiu fome e falta de energia durante a m...</td>\n",
       "      <td>O café da manhã foi esquecido.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1</td>\n",
       "      <td>As praias ficaram mais limpas e atraentes para...</td>\n",
       "      <td>A iniciativa comunitária organizou mutirões de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1</td>\n",
       "      <td>Finalmente recebeu uma oferta de trabalho em u...</td>\n",
       "      <td>Ele atualizou seu currículo e participou de vá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1</td>\n",
       "      <td>Suas peças ganharam destaque em exposições int...</td>\n",
       "      <td>O artista decidiu experimentar novas técnicas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_transformed                                           content1  \\\n",
       "0                    1   A tempestade durou várias horas durante a noite.   \n",
       "1                    1             Ele estudou intensamente para o exame.   \n",
       "2                    1          A fábrica reduziu a emissão de poluentes.   \n",
       "3                    1  Maria começou a praticar exercícios regularmente.   \n",
       "4                    1               O motor do carro parou de funcionar.   \n",
       "..                 ...                                                ...   \n",
       "95                  -1  Isso resultou na redução significativa das emi...   \n",
       "96                  -1  Ela sentiu fome e falta de energia durante a m...   \n",
       "97                  -1  As praias ficaram mais limpas e atraentes para...   \n",
       "98                  -1  Finalmente recebeu uma oferta de trabalho em u...   \n",
       "99                  -1  Suas peças ganharam destaque em exposições int...   \n",
       "\n",
       "                                             content2  \n",
       "0           Pela manhã, muitas ruas estavam alagadas.  \n",
       "1                   Conseguiu uma nota alta na prova.  \n",
       "2               A qualidade do ar na cidade melhorou.  \n",
       "3             Ela perdeu peso e aumentou sua energia.  \n",
       "4   Ele teve que chamar o guincho para levar o car...  \n",
       "..                                                ...  \n",
       "95  Após anos de pesquisa e desenvolvimento, a equ...  \n",
       "96                     O café da manhã foi esquecido.  \n",
       "97  A iniciativa comunitária organizou mutirões de...  \n",
       "98  Ele atualizou seu currículo e participou de vá...  \n",
       "99  O artista decidiu experimentar novas técnicas ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'target_transformed': [1]*50,\n",
    "    \"content1\": [\"A tempestade durou várias horas durante a noite.\", \"Ele estudou intensamente para o exame.\", \"A fábrica reduziu a emissão de poluentes.\", \"Maria começou a praticar exercícios regularmente.\", \"O motor do carro parou de funcionar.\", \"Houve uma forte seca na região.\", \"Ela começou a dormir melhor.\", \"A escola adotou uma alimentação saudável.\", \"O projeto teve apoio governamental.\", \"A internet caiu durante a reunião.\", \"Ele começou a economizar dinheiro mensalmente.\", \"A estrada estava em péssimo estado de conservação.\", \"O sistema de ar condicionado foi desligado no escritório.\", \"A empresa investiu em marketing digital.\", \"Ana não revisou o relatório antes de enviar.\", \"As crianças brincaram no parque até tarde.\", \"O curso de capacitação foi oferecido aos funcionários.\", \"Ele comprou um celular novo com câmera de alta qualidade.\", \"A reforma no prédio foi concluída.\", \"A região teve um crescimento populacional rápido.\", \"Carla começou a meditar diariamente.\", \"O atleta intensificou seu treino antes da competição.\", \"O sinal de celular na região foi ampliado.\", \"As temperaturas caíram drasticamente durante o inverno.\", \"Ele não configurou o alarme antes de dormir.\", \"A empresa ofereceu benefícios extras para seus funcionários.\", \"Houve um vazamento de gás na cozinha do restaurante.\", \"A biblioteca da escola foi modernizada com novos livros e tecnologia.\", \"Marcos passou a fazer pausas regulares durante o expediente.\", \"A empresa desenvolveu um aplicativo intuitivo para clientes.\", \"Devido ao aumento das chuvas nas últimas semanas, o nível dos rios subiu rapidamente e ultrapassou a capacidade das barragens.\", \"Ela decidiu começar uma rotina de alimentação balanceada, exercícios físicos regulares e meditação diária para melhorar sua saúde física e mental.\", \"A empresa, que sofria com baixos índices de produtividade, implementou uma nova estratégia de gestão focada no desenvolvimento dos funcionários e na cultura organizacional.\", \"O governo lançou um programa nacional de reciclagem e incentivou a participação ativa dos cidadãos por meio de campanhas de conscientização em escolas, empresas e residências.\", \"Após uma longa estiagem que afetou grande parte do território agrícola do país, o governo implementou um pacote emergencial de apoio aos agricultores, incluindo subsídios e incentivos para a recuperação das lavouras.\", \"Ele deixou o celular carregando a noite inteira sem usar carregadores de segurança e em um local sem ventilação.\", \"A comunidade local se uniu para limpar e revitalizar a praça abandonada, que estava sem manutenção há anos e havia se tornado um ponto de descarte irregular de lixo.\", \"Durante a reforma do prédio, descobriu-se que a estrutura tinha falhas graves, e o prazo para conclusão foi ampliado em seis meses para garantir a segurança.\", \"Um furacão atingiu a região costeira do país, com ventos de mais de 200 km/h, causando destruição em várias cidades e deixando milhares de pessoas desabrigadas.\", \"Ela esqueceu de regar a planta de sua varanda durante o mês todo, e o clima estava seco.\", \"João quebrou o braço jogando futebol.\", \"Devido a uma combinação de fatores climáticos extremos, incluindo ventos fortes e chuvas intensas, a região sofreu graves danos estruturais e interrupção no fornecimento de energia elétrica por vários dias.\", \"Ela esqueceu de levar o guarda-chuva.\", \"A empresa adotou práticas sustentáveis em sua produção, reduzindo o uso de plástico e implementando programas de reciclagem.\", \"A criança se recusou a comer legumes durante toda a semana.\", \"Após anos de pesquisa e desenvolvimento, a equipe científica finalmente descobriu um método eficiente para produzir energia limpa a partir de fontes renováveis.\", \"O café da manhã foi esquecido.\", \"A iniciativa comunitária organizou mutirões de limpeza nas praias locais regularmente durante o verão.\", \"Ele atualizou seu currículo e participou de várias entrevistas de emprego nos últimos meses.\", \"O artista decidiu experimentar novas técnicas em suas pinturas, incorporando elementos digitais e materiais reciclados em suas obras.\"],\n",
    "    \"content2\": [\"Pela manhã, muitas ruas estavam alagadas.\", \"Conseguiu uma nota alta na prova.\", \"A qualidade do ar na cidade melhorou.\", \"Ela perdeu peso e aumentou sua energia.\", \"Ele teve que chamar o guincho para levar o carro à oficina.\", \"As plantações foram prejudicadas, e a colheita foi menor.\", \"Sua disposição durante o dia melhorou significativamente.\", \"Os alunos passaram a ter mais energia e melhor concentração.\", \"Conseguiu concluir as fases iniciais rapidamente.\", \"A comunicação com a equipe foi interrompida.\", \"Conseguiu juntar uma quantia para uma viagem.\", \"O trânsito ficou mais lento e perigoso para os motoristas.\", \"O ambiente ficou quente e desconfortável para os funcionários.\", \"As vendas aumentaram significativamente.\", \"O documento continha erros e precisou ser corrigido.\", \"Elas ficaram cansadas e dormiram rapidamente ao chegar em casa.\", \"Eles melhoraram suas habilidades e eficiência no trabalho.\", \"Passou a tirar fotos mais nítidas e de melhor resolução.\", \"O local ficou mais seguro e esteticamente agradável.\", \"A demanda por moradias e serviços aumentou consideravelmente.\", \"Ela sentiu uma melhora no seu foco e redução do estresse.\", \"Teve um melhor desempenho e conquistou o primeiro lugar.\", \"A conexão ficou mais estável e acessível para os moradores.\", \"A procura por agasalhos e cobertores aumentou nas lojas.\", \"Acabou se atrasando para o trabalho na manhã seguinte.\", \"A satisfação e motivação dos colaboradores aumentaram.\", \"O local foi evacuado por segurança, e o serviço foi interrompido temporariamente.\", \"Os alunos começaram a frequentá-la mais e a melhorar seu desempenho acadêmico.\", \"Ele se sentiu mais produtivo e menos cansado ao final do dia.\", \"O número de usuários aumentou rapidamente.\", \"Diversas áreas urbanas e rurais foram afetadas por inundações, forçando muitas famílias a deixarem suas casas temporariamente.\", \"Em poucos meses, notou uma grande melhora em sua disposição, concentração e níveis de energia, além de perder peso.\", \"Em menos de um ano, a moral da equipe melhorou, a rotatividade diminuiu, e a produtividade geral aumentou em cerca de 30%.\", \"Como resultado, houve uma redução significativa na quantidade de resíduos sólidos em aterros e uma maior economia de recursos naturais.\", \"Em um ano, a produção agrícola voltou a níveis estáveis, e o impacto econômico negativo foi mitigado, beneficiando a população.\", \"Pela manhã, o dispositivo estava superaquecido e apresentou danos permanentes na bateria, reduzindo sua capacidade de funcionamento.\", \"Com a revitalização, a praça voltou a ser um local de encontro para moradores, e a segurança da área também melhorou.\", \"Apesar do atraso, a reforma resultou em um edifício mais seguro, confortável e com um aumento significativo no valor do imóvel.\", \"A resposta emergencial foi mobilizada rapidamente, com abrigos temporários e ajuda humanitária distribuída para minimizar o impacto nas vítimas.\", \"A planta murchou completamente e, infelizmente, não conseguiu ser recuperada, tendo que ser substituída.\", \"Ele ficou impossibilitado de trabalhar por duas semanas.\", \"A comunidade teve que recorrer a abrigos temporários, e a economia local sofreu uma queda significativa devido à paralisação das atividades comerciais.\", \"Ficou molhada durante o trajeto para o trabalho.\", \"A reputação da empresa melhorou, atraindo consumidores conscientes e aumentando as vendas em 20%.\", \"Sua mãe ficou preocupada com a falta de nutrientes na alimentação dele e decidiu consultar um nutricionista.\", \"Isso resultou na redução significativa das emissões de carbono e no avanço tecnológico sustentável, beneficiando o meio ambiente globalmente.\", \"Ela sentiu fome e falta de energia durante a manhã de trabalho.\", \"As praias ficaram mais limpas e atraentes para turistas, além de promover a conscientização ambiental entre os moradores.\", \"Finalmente recebeu uma oferta de trabalho em uma empresa renomada, melhorando sua estabilidade financeira.\", \"Suas peças ganharam destaque em exposições internacionais, ampliando seu reconhecimento e alcance no mercado de arte.\"]\n",
    "}\n",
    "\n",
    "# Crie o DataFrame\n",
    "df_validation = pd.DataFrame(data)\n",
    "\n",
    "# Adicionar novas frases com a ordem contrária e target 0\n",
    "df_reversed = pd.DataFrame({\n",
    "    'target_transformed': [-1] * len(data['target_transformed']),\n",
    "    'content1': df_validation['content2'],\n",
    "    'content2': df_validation['content1']\n",
    "})\n",
    "\n",
    "# Concatenar os dois DataFrames\n",
    "df_validation = pd.concat([df_validation, df_reversed], ignore_index=True)\n",
    "\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o collate_fn, necessária para lidar com sequências de tamanhos variáveis\n",
    "def collate_fn(batch):\n",
    "    sequences1, sequences2, targets = zip(*batch)\n",
    "    return sequences1, sequences2, torch.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dataset = SequenceDataset()\n",
    "validation_dataset = SequenceDataset_val(df_validation)\n",
    "\n",
    "# Criar DataLoaders\n",
    "\"\"\"train_dataloader = DataLoader(\n",
    "  \ttraining_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "training_dataset = InfiniteSequenceDataset(db1_path, db2_path, alias_db2)\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=32, num_workers=4)\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RegressionRNN(nn.Module):\n",
    "    def __init__(self, input_size=2048, hidden_size=256, num_layers=3):\n",
    "        super(RegressionRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = True  # Configurado como True permanentemente\n",
    "\n",
    "        # Define os RNNs para as duas sequências com bidirecionalidade\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=0.3\n",
    "        )\n",
    "\n",
    "        # Cada RNN bidirecional produz hidden_size * 2\n",
    "        # Como temos duas sequências, o tamanho final é hidden_size * 4\n",
    "        final_hidden_size = hidden_size * 4  # (hidden_size * 2) * 2\n",
    "\n",
    "        # Primeira camada totalmente conectada\n",
    "        self.fc1 = nn.Linear(final_hidden_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Segunda camada totalmente conectada para a saída\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def _process_sequences(self, sequences, rnn):\n",
    "        \"\"\"\n",
    "        Função auxiliar para processar uma lista de sequências através de um RNN.\n",
    "\n",
    "        Args:\n",
    "            sequences (list of tensors): Lista de tensores de entrada com tamanhos variados.\n",
    "            rnn (nn.LSTM): RNN a ser usado para processar as sequências.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Estado oculto concatenado de todas as sequências no batch.\n",
    "        \"\"\"\n",
    "        # Calcula os comprimentos das sequências\n",
    "        lengths = torch.tensor(\n",
    "            [seq.size(0) for seq in sequences], dtype=torch.long, device=sequences[0].device)\n",
    "\n",
    "        # Padroniza as sequências para o mesmo comprimento\n",
    "        padded_sequences = nn.utils.rnn.pad_sequence(\n",
    "            sequences, batch_first=True)\n",
    "\n",
    "        # Empacota as sequências padronizadas\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            padded_sequences,\n",
    "            lengths.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # Passa pelas camadas RNN\n",
    "        packed_output, (h_n, _) = rnn(packed_input)\n",
    "\n",
    "        # h_n tem a forma (num_layers * num_directions, batch, hidden_size)\n",
    "        # Para bidirectional=True, num_directions = 2\n",
    "        # Extraímos os estados ocultos das últimas camadas forward e backward\n",
    "        # Última camada forward: forma (batch, hidden_size)\n",
    "        h_n_forward = h_n[-2, :, :]\n",
    "        # Última camada backward: forma (batch, hidden_size)\n",
    "        h_n_backward = h_n[-1, :, :]\n",
    "\n",
    "        # Concatena os estados ocultos forward e backward\n",
    "        # forma: (batch, hidden_size * 2)\n",
    "        combined = torch.cat((h_n_forward, h_n_backward), dim=1)\n",
    "\n",
    "        return combined\n",
    "\n",
    "    def forward(self, sequences1, sequences2):\n",
    "        \"\"\"\n",
    "        Forward pass do modelo.\n",
    "\n",
    "        Args:\n",
    "            sequences1 (list of tensors): Primeira lista de sequências de entrada.\n",
    "            sequences2 (list of tensors): Segunda lista de sequências de entrada.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída de regressão para cada par de sequências.\n",
    "        \"\"\"\n",
    "        # Processa ambas as sequências usando a função auxiliar\n",
    "        last_output1 = self._process_sequences(\n",
    "            sequences1, self.rnn1)  # Forma: (batch, hidden_size * 2)\n",
    "        last_output2 = self._process_sequences(\n",
    "            sequences2, self.rnn2)  # Forma: (batch, hidden_size * 2)\n",
    "\n",
    "        # Concatena as saídas das duas sequências\n",
    "        # Forma: (batch, hidden_size * 4)\n",
    "        combined_output = torch.cat((last_output1, last_output2), dim=1)\n",
    "\n",
    "        # Passa pela primeira camada totalmente conectada\n",
    "        out = self.fc1(combined_output)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Passa pela segunda camada totalmente conectada\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out.squeeze(1)  # Forma: (batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o modelo, critério de perda e otimizador\n",
    "model_order = RegressionRNN().to('cuda')\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = nn.HuberLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model_order.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "# Inicializar o scheduler ReduceLROnPlateau\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=10, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o contador de passos\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 22:57:37.301882: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 22:57:40.818833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732154261.519002   14495 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732154262.222839   14495 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 22:57:45.506666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o writer do TensorBoard\n",
    "writer = SummaryWriter('runs/treinamento_regressao_rnn')\n",
    "\n",
    "# Envolver o loop de épocas com tqdm para mostrar o progresso das épocas\n",
    "epoch_progress = tqdm(range(num_epochs), desc='Treinamento', unit='época')\n",
    "\n",
    "for epoch in epoch_progress:\n",
    "    epoch_progress.set_description(f'Época {epoch+1}/{num_epochs}')\n",
    "\n",
    "    # Treinamento\n",
    "    model_order.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for sequences1_batch, sequences2_batch, targets_batch in train_dataloader:\n",
    "        # Mover as sequências para a GPU sem empilhar\n",
    "        sequences1_batch = [s.to('cuda') for s in sequences1_batch]\n",
    "        sequences2_batch = [s.to('cuda') for s in sequences2_batch]\n",
    "        # Alvos já estão empilhados e devem ser movidos para a GPU\n",
    "        targets_batch = targets_batch.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_order(sequences1_batch, sequences2_batch)\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "\n",
    "        # Backward pass e otimização\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * targets_batch.size(0)\n",
    "\n",
    "        # Registrar a perda de treinamento a cada passo\n",
    "        writer.add_scalar('Perda_Treinamento_Passo', loss.item(), step)\n",
    "        step += 1\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_dataloader.dataset)\n",
    "\n",
    "    # Validação\n",
    "    model_order.eval()\n",
    "    validation_loss = 0.0\n",
    "    correct_sign = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences1_batch, sequences2_batch, targets_batch in validation_dataloader:\n",
    "            # Mover as sequências para a GPU sem empilhar\n",
    "            sequences1_batch = [s.to('cuda') for s in sequences1_batch]\n",
    "            sequences2_batch = [s.to('cuda') for s in sequences2_batch]\n",
    "            # Alvos já estão empilhados e devem ser movidos para a GPU\n",
    "            targets_batch = targets_batch.to('cuda')\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_order(sequences1_batch, sequences2_batch)\n",
    "            loss = criterion(outputs, targets_batch)\n",
    "            validation_loss += loss.item() * targets_batch.size(0)\n",
    "\n",
    "            # Considerar apenas os alvos positivos ou negativos\n",
    "            non_zero_mask = targets_batch != 0\n",
    "            if non_zero_mask.sum().item() == 0:\n",
    "                continue  # Pular se não houver alvos diferentes de zero\n",
    "\n",
    "            predicted_sign = torch.sign(outputs)[non_zero_mask]\n",
    "            target_sign = torch.sign(targets_batch)[non_zero_mask]\n",
    "\n",
    "            # Calcular acertos onde os sinais correspondem\n",
    "            correct_sign += (predicted_sign == target_sign).sum().item()\n",
    "            total += non_zero_mask.sum().item()\n",
    "\n",
    "    # Evitar divisão por zero\n",
    "    if total > 0:\n",
    "        sign_accuracy = correct_sign / total\n",
    "    else:\n",
    "        sign_accuracy = 0.0\n",
    "\n",
    "    avg_validation_loss = validation_loss / len(validation_dataloader.dataset)\n",
    "\n",
    "    # Registrar as métricas de validação por época\n",
    "    writer.add_scalar('Perda_Validação_Epoca', avg_validation_loss, epoch+1)\n",
    "    writer.add_scalar('Acurácia_Sinal_Validação', sign_accuracy, epoch+1)\n",
    "\n",
    "    # Passar a perda de validação para o scheduler\n",
    "    scheduler.step(avg_validation_loss)\n",
    "\n",
    "    # Registrar a taxa de aprendizado atual (opcional)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Taxa_Aprendizado', current_lr, epoch+1)\n",
    "\n",
    "    # Atualizar a descrição da barra com as perdas atuais e acurácia do sinal\n",
    "    epoch_progress.set_postfix({\n",
    "        'Perda Treinamento': f'{avg_train_loss:.3f}',\n",
    "        'Perda Validação': f'{avg_validation_loss:.3f}',\n",
    "        'Acurácia Sinal': f'{sign_accuracy*100:.2f}%',\n",
    "        'LR': f'{current_lr:.8f}'\n",
    "    })\n",
    "\n",
    "    # Liberar cache da GPU após cada época\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Fechar o SummaryWriter ao final do treinamento\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em ./saved_fineweb/regression_rnn_model.pth\n",
      "Estado do otimizador salvo em ./saved_fineweb/optimizer_state.pth\n",
      "Checkpoint salvo em ./saved_fineweb/last_epoch.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Diretório onde os modelos serão salvos\n",
    "save_dir = './saved_fineweb'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Salvando o estado do modelo\n",
    "model_path = os.path.join(save_dir, 'regression_rnn_model.pth')\n",
    "torch.save(model_order.state_dict(), model_path)\n",
    "print(f\"Modelo salvo em {model_path}\")\n",
    "\n",
    "# Opcional: Salvando o estado do otimizador\n",
    "optimizer_path = os.path.join(save_dir, 'optimizer_state.pth')\n",
    "torch.save(optimizer.state_dict(), optimizer_path)\n",
    "print(f\"Estado do otimizador salvo em {optimizer_path}\")\n",
    "\n",
    "# Opcional: Salvar a época atual para retomar o treinamento\n",
    "epoch_path = os.path.join(save_dir, 'last_epoch.pth')\n",
    "torch.save({'epoch': epoch, 'model_state_dict': model_order.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_validation_loss}, epoch_path)\n",
    "print(f\"Checkpoint salvo em {epoch_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_386141/3511341442.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_order.load_state_dict(torch.load(model_path, map_location='cuda'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RegressionRNN(\n",
       "  (rnn1): LSTM(2048, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (rnn2): LSTM(2048, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join('./saved_fineweb', 'regression_rnn_model.pth')\n",
    "\n",
    "# Carregar o estado do modelo\n",
    "model_order.load_state_dict(torch.load(model_path, map_location='cuda'))\n",
    "\n",
    "# Colocar o modelo em modo de avaliação\n",
    "model_order.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da previsão para o par 1: -0.030401533469557762\n",
      "Resultado da previsão para o par 2: -0.030401533469557762\n",
      "Resultado da previsão para o par 3: -0.030401533469557762\n",
      "Resultado da previsão para o par 4: -0.030401533469557762\n",
      "Resultado da previsão para o par 5: -0.030401533469557762\n",
      "Resultado da previsão para o par 6: -0.030401533469557762\n",
      "Resultado da previsão para o par 7: -0.030401533469557762\n",
      "Resultado da previsão para o par 8: -0.030401533469557762\n",
      "Resultado da previsão para o par 9: -0.030401533469557762\n",
      "Resultado da previsão para o par 10: -0.030401533469557762\n",
      "Resultado da previsão para o par 11: -0.030401533469557762\n",
      "Resultado da previsão para o par 12: -0.030401533469557762\n",
      "Resultado da previsão para o par 13: -0.030401533469557762\n",
      "Resultado da previsão para o par 14: -0.030401533469557762\n",
      "Resultado da previsão para o par 15: -0.030401533469557762\n",
      "Resultado da previsão para o par 16: -0.030401533469557762\n",
      "Resultado da previsão para o par 17: -0.030401533469557762\n",
      "Resultado da previsão para o par 18: -0.030401533469557762\n",
      "Resultado da previsão para o par 19: -0.030401533469557762\n",
      "Resultado da previsão para o par 20: -0.030401533469557762\n",
      "Resultado da previsão para o par 21: -0.030401533469557762\n",
      "Resultado da previsão para o par 22: -0.030401533469557762\n",
      "Resultado da previsão para o par 23: -0.030401533469557762\n",
      "Resultado da previsão para o par 24: -0.030401533469557762\n",
      "Resultado da previsão para o par 25: -0.030401533469557762\n",
      "Resultado da previsão para o par 26: -0.030401533469557762\n",
      "Resultado da previsão para o par 27: -0.030401533469557762\n",
      "Resultado da previsão para o par 28: -0.030401533469557762\n",
      "Resultado da previsão para o par 29: -0.030401533469557762\n",
      "Resultado da previsão para o par 30: -0.030401533469557762\n",
      "Resultado da previsão para o par 31: -0.030401533469557762\n",
      "Resultado da previsão para o par 32: -0.030401533469557762\n",
      "Resultado da previsão para o par 33: -0.030401533469557762\n",
      "Resultado da previsão para o par 34: -0.030401533469557762\n",
      "Resultado da previsão para o par 35: -0.030401533469557762\n",
      "Resultado da previsão para o par 36: -0.030401533469557762\n",
      "Resultado da previsão para o par 37: -0.030401533469557762\n",
      "Resultado da previsão para o par 38: -0.030401533469557762\n",
      "Resultado da previsão para o par 39: -0.030401533469557762\n",
      "Resultado da previsão para o par 40: -0.030401533469557762\n",
      "Resultado da previsão para o par 41: -0.030401533469557762\n",
      "Resultado da previsão para o par 42: -0.030401533469557762\n",
      "Resultado da previsão para o par 43: -0.030401533469557762\n",
      "Resultado da previsão para o par 44: -0.030401533469557762\n",
      "Resultado da previsão para o par 45: -0.030401533469557762\n",
      "Resultado da previsão para o par 46: -0.030401533469557762\n",
      "Resultado da previsão para o par 47: -0.030401533469557762\n",
      "Resultado da previsão para o par 48: -0.030401533469557762\n",
      "Resultado da previsão para o par 49: -0.030401533469557762\n",
      "Resultado da previsão para o par 50: -0.030401533469557762\n",
      "Resultado da previsão para o par 51: -0.030401533469557762\n",
      "Resultado da previsão para o par 52: -0.030401533469557762\n",
      "Resultado da previsão para o par 53: -0.030401533469557762\n",
      "Resultado da previsão para o par 54: -0.030401533469557762\n",
      "Resultado da previsão para o par 55: -0.030401533469557762\n",
      "Resultado da previsão para o par 56: -0.030401533469557762\n",
      "Resultado da previsão para o par 57: -0.030401533469557762\n",
      "Resultado da previsão para o par 58: -0.030401533469557762\n",
      "Resultado da previsão para o par 59: -0.030401533469557762\n",
      "Resultado da previsão para o par 60: -0.030401533469557762\n",
      "Resultado da previsão para o par 61: -0.030401533469557762\n",
      "Resultado da previsão para o par 62: -0.030401533469557762\n",
      "Resultado da previsão para o par 63: -0.030401533469557762\n",
      "Resultado da previsão para o par 64: -0.030401533469557762\n",
      "Resultado da previsão para o par 65: -0.030401533469557762\n",
      "Resultado da previsão para o par 66: -0.030401533469557762\n",
      "Resultado da previsão para o par 67: -0.030401533469557762\n",
      "Resultado da previsão para o par 68: -0.030401533469557762\n",
      "Resultado da previsão para o par 69: -0.030401533469557762\n",
      "Resultado da previsão para o par 70: -0.030401533469557762\n",
      "Resultado da previsão para o par 71: -0.030401533469557762\n",
      "Resultado da previsão para o par 72: -0.030401533469557762\n",
      "Resultado da previsão para o par 73: -0.030401533469557762\n",
      "Resultado da previsão para o par 74: -0.030401533469557762\n",
      "Resultado da previsão para o par 75: -0.030401533469557762\n",
      "Resultado da previsão para o par 76: -0.030401533469557762\n",
      "Resultado da previsão para o par 77: -0.030401533469557762\n",
      "Resultado da previsão para o par 78: -0.030401533469557762\n",
      "Resultado da previsão para o par 79: -0.030401533469557762\n",
      "Resultado da previsão para o par 80: -0.030401533469557762\n",
      "Resultado da previsão para o par 81: -0.030401533469557762\n",
      "Resultado da previsão para o par 82: -0.030401533469557762\n",
      "Resultado da previsão para o par 83: -0.030401533469557762\n",
      "Resultado da previsão para o par 84: -0.030401533469557762\n",
      "Resultado da previsão para o par 85: -0.030401533469557762\n",
      "Resultado da previsão para o par 86: -0.030401533469557762\n",
      "Resultado da previsão para o par 87: -0.030401533469557762\n",
      "Resultado da previsão para o par 88: -0.030401533469557762\n",
      "Resultado da previsão para o par 89: -0.030401533469557762\n",
      "Resultado da previsão para o par 90: -0.030401533469557762\n",
      "Resultado da previsão para o par 91: -0.030401533469557762\n",
      "Resultado da previsão para o par 92: -0.030401533469557762\n",
      "Resultado da previsão para o par 93: -0.030401533469557762\n",
      "Resultado da previsão para o par 94: -0.030401533469557762\n",
      "Resultado da previsão para o par 95: -0.030401533469557762\n",
      "Resultado da previsão para o par 96: -0.030401533469557762\n",
      "Resultado da previsão para o par 97: -0.030401533469557762\n",
      "Resultado da previsão para o par 98: -0.030401533469557762\n",
      "Resultado da previsão para o par 99: -0.030401533469557762\n",
      "Resultado da previsão para o par 100: -0.030401533469557762\n"
     ]
    }
   ],
   "source": [
    "model_order.eval()\n",
    "\n",
    "sequences1 = [text_to_embedding(text).to('cuda') for text in df_validation['content1']]\n",
    "sequences2 = [text_to_embedding(text).to('cuda') for text in df_validation['content2']]\n",
    "\n",
    "# Realizar a previsão\n",
    "with torch.no_grad():\n",
    "    output = model_order(sequences1, sequences2)\n",
    "\n",
    "# Imprimir os resultados da previsão\n",
    "for i, pred in enumerate(output):\n",
    "    print(f\"Resultado da previsão para o par {i+1}: {pred.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Inversa da Diferença Absoluta\n",
      "Correlação de Pearson: nan\n",
      "Correlação de Spearman: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22901/1158226715.py:30: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
      "/tmp/ipykernel_22901/1158226715.py:31: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  spearman_corr, _ = spearmanr(true_scores, pred_scores)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Carregar o conjunto de dados de avaliação (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Listas para armazenar as pontuações reais e as previsões do modelo\n",
    "true_scores = []\n",
    "pred_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in eval_dataset:\n",
    "        sent1 = example['sentence1']\n",
    "        sent2 = example['sentence2']\n",
    "        score = example['score']\n",
    "\n",
    "        # Gerar embeddings para ambas as sentenças\n",
    "        embedding1 = text_to_embedding(sent1).to('cuda')\n",
    "        embedding2 = text_to_embedding(sent2).to('cuda')\n",
    "\n",
    "        # Obter a previsão do modelo\n",
    "        prediction = model_order([embedding1], [embedding2])\n",
    "        pred_score = 1 / (1 + abs(prediction.item()))\n",
    "\n",
    "        # Armazenar as pontuações\n",
    "        true_scores.append(score)\n",
    "        pred_scores.append(pred_score)\n",
    "\n",
    "# Calcular as métricas de correlação\n",
    "pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "\n",
    "print(\"Similaridade Inversa da Diferença Absoluta\")\n",
    "print(f\"Correlação de Pearson: {pearson_corr:.4f}\")\n",
    "print(f\"Correlação de Spearman: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando exemplos: 100%|██████████| 1500/1500 [00:05<00:00, 290.57it/s]\n",
      "Buscando o melhor k: 100%|██████████| 9990/9990 [00:14<00:00, 713.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Baseada em Exponencial\n",
      "Melhor valor de k: 0.2799999999999999\n",
      "Correlação de Pearson: 0.0355\n",
      "Correlação de Spearman: 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm import tqdm  # Para acompanhar o progresso\n",
    "\n",
    "# Carregar o conjunto de dados de avaliação (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Definir o intervalo de valores de k a serem testados\n",
    "k_values = np.arange(0.001, 100.0, 0.01)\n",
    "best_k = None\n",
    "best_pearson = -1  # Inicialização com um valor baixo\n",
    "best_spearman = -1\n",
    "\n",
    "# Pré-computar todas as predições para evitar recalcular múltiplas vezes\n",
    "true_scores = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in tqdm(eval_dataset, desc=\"Processando exemplos\"):\n",
    "        sent1 = example['sentence1']\n",
    "        sent2 = example['sentence2']\n",
    "        score = example['score']\n",
    "\n",
    "        # Gerar embeddings para ambas as sentenças\n",
    "        embedding1 = text_to_embedding(sent1).to('cuda')\n",
    "        embedding2 = text_to_embedding(sent2).to('cuda')\n",
    "\n",
    "        # Obter a previsão do modelo\n",
    "        prediction = model_order([embedding1], [embedding2])\n",
    "        predictions.append(prediction.item())\n",
    "\n",
    "        # Armazenar as pontuações reais\n",
    "        true_scores.append(score)\n",
    "\n",
    "true_scores = np.array(true_scores)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Iterar sobre os valores de k para encontrar o melhor\n",
    "for k in tqdm(k_values, desc=\"Buscando o melhor k\"):\n",
    "    pred_scores = np.exp(-k * np.abs(predictions))\n",
    "    \n",
    "    pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "    spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "    \n",
    "    # Verificar se este k é o melhor até agora\n",
    "    if pearson_corr > best_pearson:\n",
    "        best_pearson = pearson_corr\n",
    "        best_spearman = spearman_corr\n",
    "        best_k = k\n",
    "\n",
    "print(\"Similaridade Baseada em Exponencial\")\n",
    "print(f\"Melhor valor de k: {best_k}\")\n",
    "print(f\"Correlação de Pearson: {best_pearson:.4f}\")\n",
    "print(f\"Correlação de Spearman: {best_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação de Pearson: 0.8806\n",
      "Correlação de Spearman: 0.8810\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Verificar se CUDA está disponível\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Carregar o modelo SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\").to(device)\n",
    "\n",
    "# Carregar o conjunto de dados de avaliação (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Listas para armazenar as pontuações reais e as previsões do modelo\n",
    "true_scores = []\n",
    "pred_scores = []\n",
    "\n",
    "# Obter as sentenças e os escores do conjunto de dados\n",
    "sentences1 = eval_dataset['sentence1']\n",
    "sentences2 = eval_dataset['sentence2']\n",
    "scores = eval_dataset['score']\n",
    "\n",
    "# Processar uma frase por vez\n",
    "for i in range(len(eval_dataset)):\n",
    "    sentence1 = sentences1[i]\n",
    "    sentence2 = sentences2[i]\n",
    "    true_score = scores[i]\n",
    "\n",
    "    # Gerar embeddings para ambas as sentenças individualmente\n",
    "    embedding1 = model.encode(sentence1, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "    embedding2 = model.encode(sentence2, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "\n",
    "    # Calcular a similaridade cosseno\n",
    "    cosine_score = util.cos_sim(embedding1, embedding2).item()\n",
    "\n",
    "    # Escalar a similaridade cosseno de [-1, 1] para [0, 1]\n",
    "    scaled_score = (cosine_score + 1) / 2\n",
    "\n",
    "    # Armazenar as pontuações\n",
    "    true_scores.append(true_score)\n",
    "    pred_scores.append(scaled_score)\n",
    "\n",
    "# Calcular as métricas de correlação\n",
    "pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "\n",
    "print(f\"Correlação de Pearson: {pearson_corr:.4f}\")\n",
    "print(f\"Correlação de Spearman: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SentenceTransformer' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Realizar a previsão\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m model_order(\n\u001b[0;32m---> 13\u001b[0m         [text_to_embedding(\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO aluno estudou para o exame durante a noite.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[1;32m     15\u001b[0m         [text_to_embedding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO resultado foi excelente devido à dedicação.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Imprimir a saída da regressão\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultado da previsão:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mtext_to_embedding\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_tokens(input_ids)  \u001b[38;5;66;03m# [1,2048] até [1024,2048]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39mcpu()  \u001b[38;5;66;03m# Move para CPU\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SentenceTransformer' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = os.path.join('./saved_HuberLoss', 'regression_rnn_model.pth')\n",
    "\n",
    "# Carregar o estado do modelo\n",
    "#model_order.load_state_dict(torch.load(model_path, map_location='cuda'))\n",
    "\n",
    "# Colocar o modelo em modo de avaliação\n",
    "model_order.eval()\n",
    "\n",
    "# Realizar a previsão\n",
    "with torch.no_grad():\n",
    "    output = model_order(\n",
    "        [text_to_embedding(\n",
    "            \"O aluno estudou para o exame durante a noite.\").to('cuda')],\n",
    "        [text_to_embedding(\"O resultado foi excelente devido à dedicação.\").to('cuda')])\n",
    "\n",
    "# Imprimir a saída da regressão\n",
    "print(\"Resultado da previsão:\", output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2203"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_order  # Remove a referência ao modelo\n",
    "\n",
    "# Libera a memória da GPU, se o modelo estiver usando CUDA\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Força a coleta de lixo\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
