{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B\", legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Conectar ou criar o banco de dados DuckDB\n",
    "conn = duckdb.connect('train_dataset2.duckdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Please ensure you have a compatible GPU and drivers installed.\")\n",
    "else:\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at ./Llama-3.2-1b-Gather/ and are newly initialized: ['model.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 2048)\n",
      "    (layers): ModuleList()\n",
      "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Recarrega o modelo salvo\n",
    "model = AutoModelForCausalLM.from_pretrained('./Llama-3.2-1b-Gather/').to('cpu')\n",
    "\n",
    "# Verifica a estrutura do modelo recarregado\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_embedding(input_text):\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to('cpu')\n",
    "        embedding = model.model.embed_tokens(input_ids) # [1,2048] até [1024,2048]\n",
    "        embedding = embedding.cpu()  # Move para CPU\n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "#logger = logging.getLogger(__name__)\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #start_time = time.time()\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "        sequence1 = text_to_embedding(row['content1'])\n",
    "        sequence2 = text_to_embedding(row['content2'])\n",
    "        \n",
    "        # Use the transformed target\n",
    "        target = torch.tensor(row['target'], dtype=torch.float32)\n",
    "        \n",
    "        # Convert sequences to tensors (no need to reconvert embedding)\n",
    "        sequence1 = sequence1.float()\n",
    "        sequence2 = sequence2.float()\n",
    "        \n",
    "        #end_time = time.time()\n",
    "        #if idx % 1000 == 0:\n",
    "        #    logger.info(f\"Processing sample {idx}/{len(self.df)} - Time: {end_time - start_time:.4f}s\")\n",
    "        \n",
    "        return sequence1, sequence2, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792def5c59234962959a11511ec78112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice1</th>\n",
       "      <th>indice2</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212566</td>\n",
       "      <td>475011</td>\n",
       "      <td>lado o capitalismo aparecerá aos</td>\n",
       "      <td>hugo chávez em 27 de maio de 2007 e teve sua s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447730</td>\n",
       "      <td>1075483</td>\n",
       "      <td>grupos globalistas bilionários os metacapitali...</td>\n",
       "      <td>índio e um metalúrgico podem chegar à presidên...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>835853</td>\n",
       "      <td>531647</td>\n",
       "      <td>matemática que usou os instrumentos da sua dis...</td>\n",
       "      <td>o candidato e sabe a que veio é essa a condiçã...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084589</td>\n",
       "      <td>219455</td>\n",
       "      <td>e função no plano geral da</td>\n",
       "      <td>atrasar têm sentidos ambíguos que se alternam ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1112381</td>\n",
       "      <td>438128</td>\n",
       "      <td>pânico na casa branca tirar o sono do papa ou ...</td>\n",
       "      <td>um progresso da democracia 23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63995</th>\n",
       "      <td>1037805</td>\n",
       "      <td>819313</td>\n",
       "      <td>homossexual vem num tom de quem advogasse medi...</td>\n",
       "      <td>que importa não é conhecer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63996</th>\n",
       "      <td>247199</td>\n",
       "      <td>742582</td>\n",
       "      <td>mataram acidentalmente trinta civis</td>\n",
       "      <td>necessitará largar na ociosidade uma boa parce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63997</th>\n",
       "      <td>651390</td>\n",
       "      <td>592042</td>\n",
       "      <td>brasil os discursos revolucionários</td>\n",
       "      <td>quanto incompreensíveis e condenando</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63998</th>\n",
       "      <td>427763</td>\n",
       "      <td>415440</td>\n",
       "      <td>a transformar seus órgãos de mídia em megafone...</td>\n",
       "      <td>dessa regra vem alcançando sucesso é que enqua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63999</th>\n",
       "      <td>265776</td>\n",
       "      <td>998966</td>\n",
       "      <td>a congelarse a ser</td>\n",
       "      <td>soberano de uma nova autoridade</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       indice1  indice2                                           content1  \\\n",
       "0       212566   475011                   lado o capitalismo aparecerá aos   \n",
       "1       447730  1075483  grupos globalistas bilionários os metacapitali...   \n",
       "2       835853   531647  matemática que usou os instrumentos da sua dis...   \n",
       "3      1084589   219455                         e função no plano geral da   \n",
       "4      1112381   438128  pânico na casa branca tirar o sono do papa ou ...   \n",
       "...        ...      ...                                                ...   \n",
       "63995  1037805   819313  homossexual vem num tom de quem advogasse medi...   \n",
       "63996   247199   742582                mataram acidentalmente trinta civis   \n",
       "63997   651390   592042                brasil os discursos revolucionários   \n",
       "63998   427763   415440  a transformar seus órgãos de mídia em megafone...   \n",
       "63999   265776   998966                                 a congelarse a ser   \n",
       "\n",
       "                                                content2  target  \n",
       "0      hugo chávez em 27 de maio de 2007 e teve sua s...       1  \n",
       "1      índio e um metalúrgico podem chegar à presidên...       1  \n",
       "2      o candidato e sabe a que veio é essa a condiçã...       0  \n",
       "3      atrasar têm sentidos ambíguos que se alternam ...       0  \n",
       "4                          um progresso da democracia 23       0  \n",
       "...                                                  ...     ...  \n",
       "63995                         que importa não é conhecer       0  \n",
       "63996  necessitará largar na ociosidade uma boa parce...       1  \n",
       "63997               quanto incompreensíveis e condenando       0  \n",
       "63998  dessa regra vem alcançando sucesso é que enqua...       0  \n",
       "63999                    soberano de uma nova autoridade       1  \n",
       "\n",
       "[64000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = conn.execute(\"\"\"\n",
    "WITH random_indices AS (\n",
    "  SELECT id, indice, content\n",
    "  FROM dataset\n",
    "  WHERE type = 1\n",
    "  ORDER BY RANDOM()\n",
    ")\n",
    "SELECT\n",
    "  a.indice AS indice1,\n",
    "  b.indice AS indice2,\n",
    "  a.content AS content1,\n",
    "  b.content AS content2,\n",
    "  CASE \n",
    "    WHEN a.indice > b.indice THEN 0\n",
    "    ELSE 1\n",
    "  END AS target\n",
    "FROM random_indices a\n",
    "JOIN random_indices b\n",
    "  ON a.id != b.id\n",
    "ORDER BY RANDOM()\n",
    "LIMIT 64000;\n",
    "\"\"\").df()\n",
    "\n",
    "# Compute the index difference\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A tempestade durou várias horas durante a noite.</td>\n",
       "      <td>Pela manhã, muitas ruas estavam alagadas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ele estudou intensamente para o exame.</td>\n",
       "      <td>Conseguir uma nota alta na prova.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A fábrica reduziu a emissão de poluentes.</td>\n",
       "      <td>A qualidade do ar na cidade melhorou significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Maria começou a praticar exercícios regularmente.</td>\n",
       "      <td>Ela perdeu peso e aumentou sua energia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O trânsito intenso durante a manhã atrasou o ô...</td>\n",
       "      <td>Muitas pessoas chegaram atrasadas ao trabalho.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>A empresa investiu em tecnologia de ponta.</td>\n",
       "      <td>A produção aumentou e os custos diminuíram.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>A empresa adotou um sistema de trabalho remoto.</td>\n",
       "      <td>Os funcionários tiveram maior flexibilidade e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>A escola implementou aulas de reforço após o e...</td>\n",
       "      <td>O desempenho acadêmico dos alunos melhorou sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>A falta de irrigação adequada prejudicou as pl...</td>\n",
       "      <td>A colheita deste ano foi muito menor do que o ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>João começou a acordar mais cedo todos os dias.</td>\n",
       "      <td>Ele conseguiu concluir suas tarefas antes do h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>A falta de manutenção no sistema elétrico caus...</td>\n",
       "      <td>Houve um apagão que afetou toda a vizinhança p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Ana adotou uma alimentação mais saudável e bal...</td>\n",
       "      <td>Ela notou uma melhora significativa em sua saú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>A biblioteca expandiu seu acervo com novos liv...</td>\n",
       "      <td>O número de visitantes aumentou significativam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Carlos decidiu aprender a programar em Python.</td>\n",
       "      <td>Ele conseguiu um emprego melhor na área de tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>A chuva intensa causou inundações nas áreas ba...</td>\n",
       "      <td>Muitas casas foram danificadas e moradores tiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Paula participou de um curso de liderança.</td>\n",
       "      <td>Ela foi promovida a gerente na empresa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>O avião enfrentou uma forte turbulência durant...</td>\n",
       "      <td>Muitos passageiros ficaram assustados e alguns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>A cidade implementou ciclovias em várias áreas.</td>\n",
       "      <td>Houve um aumento no número de pessoas que util...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Pela manhã, muitas ruas estavam alagadas.</td>\n",
       "      <td>A tempestade durou várias horas durante a noite.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Conseguir uma nota alta na prova.</td>\n",
       "      <td>Ele estudou intensamente para o exame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>A qualidade do ar na cidade melhorou significa...</td>\n",
       "      <td>A fábrica reduziu a emissão de poluentes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>Ela perdeu peso e aumentou sua energia.</td>\n",
       "      <td>Maria começou a praticar exercícios regularmente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>Muitas pessoas chegaram atrasadas ao trabalho.</td>\n",
       "      <td>O trânsito intenso durante a manhã atrasou o ô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>A produção aumentou e os custos diminuíram.</td>\n",
       "      <td>A empresa investiu em tecnologia de ponta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>Os funcionários tiveram maior flexibilidade e ...</td>\n",
       "      <td>A empresa adotou um sistema de trabalho remoto.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>O desempenho acadêmico dos alunos melhorou sig...</td>\n",
       "      <td>A escola implementou aulas de reforço após o e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>A colheita deste ano foi muito menor do que o ...</td>\n",
       "      <td>A falta de irrigação adequada prejudicou as pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Ele conseguiu concluir suas tarefas antes do h...</td>\n",
       "      <td>João começou a acordar mais cedo todos os dias.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Houve um apagão que afetou toda a vizinhança p...</td>\n",
       "      <td>A falta de manutenção no sistema elétrico caus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>Ela notou uma melhora significativa em sua saú...</td>\n",
       "      <td>Ana adotou uma alimentação mais saudável e bal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>O número de visitantes aumentou significativam...</td>\n",
       "      <td>A biblioteca expandiu seu acervo com novos liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>Ele conseguiu um emprego melhor na área de tec...</td>\n",
       "      <td>Carlos decidiu aprender a programar em Python.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>Muitas casas foram danificadas e moradores tiv...</td>\n",
       "      <td>A chuva intensa causou inundações nas áreas ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>Ela foi promovida a gerente na empresa.</td>\n",
       "      <td>Paula participou de um curso de liderança.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>Muitos passageiros ficaram assustados e alguns...</td>\n",
       "      <td>O avião enfrentou uma forte turbulência durant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>Houve um aumento no número de pessoas que util...</td>\n",
       "      <td>A cidade implementou ciclovias em várias áreas.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                           content1  \\\n",
       "0        1   A tempestade durou várias horas durante a noite.   \n",
       "1        1             Ele estudou intensamente para o exame.   \n",
       "2        1          A fábrica reduziu a emissão de poluentes.   \n",
       "3        1  Maria começou a praticar exercícios regularmente.   \n",
       "4        1  O trânsito intenso durante a manhã atrasou o ô...   \n",
       "5        1         A empresa investiu em tecnologia de ponta.   \n",
       "6        1    A empresa adotou um sistema de trabalho remoto.   \n",
       "7        1  A escola implementou aulas de reforço após o e...   \n",
       "8        1  A falta de irrigação adequada prejudicou as pl...   \n",
       "9        1    João começou a acordar mais cedo todos os dias.   \n",
       "10       1  A falta de manutenção no sistema elétrico caus...   \n",
       "11       1  Ana adotou uma alimentação mais saudável e bal...   \n",
       "12       1  A biblioteca expandiu seu acervo com novos liv...   \n",
       "13       1     Carlos decidiu aprender a programar em Python.   \n",
       "14       1  A chuva intensa causou inundações nas áreas ba...   \n",
       "15       1         Paula participou de um curso de liderança.   \n",
       "16       1  O avião enfrentou uma forte turbulência durant...   \n",
       "17       1    A cidade implementou ciclovias em várias áreas.   \n",
       "18       0          Pela manhã, muitas ruas estavam alagadas.   \n",
       "19       0                  Conseguir uma nota alta na prova.   \n",
       "20       0  A qualidade do ar na cidade melhorou significa...   \n",
       "21       0            Ela perdeu peso e aumentou sua energia.   \n",
       "22       0     Muitas pessoas chegaram atrasadas ao trabalho.   \n",
       "23       0        A produção aumentou e os custos diminuíram.   \n",
       "24       0  Os funcionários tiveram maior flexibilidade e ...   \n",
       "25       0  O desempenho acadêmico dos alunos melhorou sig...   \n",
       "26       0  A colheita deste ano foi muito menor do que o ...   \n",
       "27       0  Ele conseguiu concluir suas tarefas antes do h...   \n",
       "28       0  Houve um apagão que afetou toda a vizinhança p...   \n",
       "29       0  Ela notou uma melhora significativa em sua saú...   \n",
       "30       0  O número de visitantes aumentou significativam...   \n",
       "31       0  Ele conseguiu um emprego melhor na área de tec...   \n",
       "32       0  Muitas casas foram danificadas e moradores tiv...   \n",
       "33       0            Ela foi promovida a gerente na empresa.   \n",
       "34       0  Muitos passageiros ficaram assustados e alguns...   \n",
       "35       0  Houve um aumento no número de pessoas que util...   \n",
       "\n",
       "                                             content2  \n",
       "0           Pela manhã, muitas ruas estavam alagadas.  \n",
       "1                   Conseguir uma nota alta na prova.  \n",
       "2   A qualidade do ar na cidade melhorou significa...  \n",
       "3             Ela perdeu peso e aumentou sua energia.  \n",
       "4      Muitas pessoas chegaram atrasadas ao trabalho.  \n",
       "5         A produção aumentou e os custos diminuíram.  \n",
       "6   Os funcionários tiveram maior flexibilidade e ...  \n",
       "7   O desempenho acadêmico dos alunos melhorou sig...  \n",
       "8   A colheita deste ano foi muito menor do que o ...  \n",
       "9   Ele conseguiu concluir suas tarefas antes do h...  \n",
       "10  Houve um apagão que afetou toda a vizinhança p...  \n",
       "11  Ela notou uma melhora significativa em sua saú...  \n",
       "12  O número de visitantes aumentou significativam...  \n",
       "13  Ele conseguiu um emprego melhor na área de tec...  \n",
       "14  Muitas casas foram danificadas e moradores tiv...  \n",
       "15            Ela foi promovida a gerente na empresa.  \n",
       "16  Muitos passageiros ficaram assustados e alguns...  \n",
       "17  Houve um aumento no número de pessoas que util...  \n",
       "18   A tempestade durou várias horas durante a noite.  \n",
       "19             Ele estudou intensamente para o exame.  \n",
       "20          A fábrica reduziu a emissão de poluentes.  \n",
       "21  Maria começou a praticar exercícios regularmente.  \n",
       "22  O trânsito intenso durante a manhã atrasou o ô...  \n",
       "23         A empresa investiu em tecnologia de ponta.  \n",
       "24    A empresa adotou um sistema de trabalho remoto.  \n",
       "25  A escola implementou aulas de reforço após o e...  \n",
       "26  A falta de irrigação adequada prejudicou as pl...  \n",
       "27    João começou a acordar mais cedo todos os dias.  \n",
       "28  A falta de manutenção no sistema elétrico caus...  \n",
       "29  Ana adotou uma alimentação mais saudável e bal...  \n",
       "30  A biblioteca expandiu seu acervo com novos liv...  \n",
       "31     Carlos decidiu aprender a programar em Python.  \n",
       "32  A chuva intensa causou inundações nas áreas ba...  \n",
       "33         Paula participou de um curso de liderança.  \n",
       "34  O avião enfrentou uma forte turbulência durant...  \n",
       "35    A cidade implementou ciclovias em várias áreas.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'target': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'content1': [\n",
    "        'A tempestade durou várias horas durante a noite.',\n",
    "        'Ele estudou intensamente para o exame.',\n",
    "        'A fábrica reduziu a emissão de poluentes.',\n",
    "        'Maria começou a praticar exercícios regularmente.',\n",
    "        'O trânsito intenso durante a manhã atrasou o ônibus.',\n",
    "        'A empresa investiu em tecnologia de ponta.',\n",
    "        'A empresa adotou um sistema de trabalho remoto.',\n",
    "        'A escola implementou aulas de reforço após o expediente.',\n",
    "        'A falta de irrigação adequada prejudicou as plantações.',\n",
    "        'João começou a acordar mais cedo todos os dias.',\n",
    "        'A falta de manutenção no sistema elétrico causou um curto-circuito.',\n",
    "        'Ana adotou uma alimentação mais saudável e balanceada.',\n",
    "        'A biblioteca expandiu seu acervo com novos livros e recursos digitais.',\n",
    "        'Carlos decidiu aprender a programar em Python.',\n",
    "        'A chuva intensa causou inundações nas áreas baixas.',\n",
    "        'Paula participou de um curso de liderança.',\n",
    "        'O avião enfrentou uma forte turbulência durante o voo.',\n",
    "        'A cidade implementou ciclovias em várias áreas.'\n",
    "    ],\n",
    "    'content2': [\n",
    "        'Pela manhã, muitas ruas estavam alagadas.',\n",
    "        'Conseguir uma nota alta na prova.',\n",
    "        'A qualidade do ar na cidade melhorou significativamente.',\n",
    "        'Ela perdeu peso e aumentou sua energia.',\n",
    "        'Muitas pessoas chegaram atrasadas ao trabalho.',\n",
    "        'A produção aumentou e os custos diminuíram.',\n",
    "        'Os funcionários tiveram maior flexibilidade e a produtividade aumentou.',\n",
    "        'O desempenho acadêmico dos alunos melhorou significativamente.',\n",
    "        'A colheita deste ano foi muito menor do que o esperado.',\n",
    "        'Ele conseguiu concluir suas tarefas antes do horário de trabalho.',\n",
    "        'Houve um apagão que afetou toda a vizinhança por várias horas.',\n",
    "        'Ela notou uma melhora significativa em sua saúde e disposição.',\n",
    "        'O número de visitantes aumentou significativamente, beneficiando estudantes e pesquisadores.',\n",
    "        'Ele conseguiu um emprego melhor na área de tecnologia.',\n",
    "        'Muitas casas foram danificadas e moradores tiveram que ser realocados.',\n",
    "        'Ela foi promovida a gerente na empresa.',\n",
    "        'Muitos passageiros ficaram assustados e alguns tiveram que receber atendimento médico.',\n",
    "        'Houve um aumento no número de pessoas que utilizam bicicletas para se deslocar, reduzindo o trânsito e a poluição.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Crie o DataFrame\n",
    "df_validation = pd.DataFrame(data)\n",
    "\n",
    "# Adicionar novas frases com a ordem contrária e target 0\n",
    "df_reversed = pd.DataFrame({\n",
    "    'target': [0] * len(data['target']),\n",
    "    'content1': df_validation['content2'],\n",
    "    'content2': df_validation['content1']\n",
    "})\n",
    "\n",
    "# Concatenar os dois DataFrames\n",
    "df_validation = pd.concat([df_validation, df_reversed], ignore_index=True)\n",
    "\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o collate_fn, necessária para lidar com sequências de tamanhos variáveis\n",
    "def collate_fn(batch):\n",
    "    sequences1, sequences2, targets = zip(*batch)\n",
    "    return sequences1, sequences2, torch.stack(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = SequenceDataset(df_training)\n",
    "validation_dataset = SequenceDataset(df_validation)\n",
    "\n",
    "# Criar DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    training_dataset, \n",
    "    batch_size=100, \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    pin_memory=False, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset, \n",
    "    batch_size=18, \n",
    "    shuffle=False, \n",
    "    num_workers=0, \n",
    "    pin_memory=False, \n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RegressionRNN(nn.Module):\n",
    "    def __init__(self, input_size=2048, hidden_size=128, num_layers=2):\n",
    "        super(RegressionRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = True  # Configurado como True permanentemente\n",
    "\n",
    "        # Define os RNNs para as duas sequências com bidirecionalidade\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        \n",
    "        # Cada RNN bidirecional produz hidden_size * 2\n",
    "        # Como temos duas sequências, o tamanho final é hidden_size * 4\n",
    "        final_hidden_size = hidden_size * 4  # (hidden_size * 2) * 2\n",
    "        \n",
    "        # Primeira camada totalmente conectada\n",
    "        self.fc1 = nn.Linear(final_hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Segunda camada totalmente conectada para a saída\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def _process_sequences(self, sequences, rnn):\n",
    "        \"\"\"\n",
    "        Função auxiliar para processar uma lista de sequências através de um RNN.\n",
    "\n",
    "        Args:\n",
    "            sequences (list of tensors): Lista de tensores de entrada com tamanhos variados.\n",
    "            rnn (nn.LSTM): RNN a ser usado para processar as sequências.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Estado oculto concatenado de todas as sequências no batch.\n",
    "        \"\"\"\n",
    "        # Calcula os comprimentos das sequências\n",
    "        lengths = torch.tensor([seq.size(0) for seq in sequences], dtype=torch.long, device=sequences[0].device)\n",
    "        \n",
    "        # Padroniza as sequências para o mesmo comprimento\n",
    "        padded_sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "        \n",
    "        # Empacota as sequências padronizadas\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            padded_sequences, \n",
    "            lengths.cpu(), \n",
    "            batch_first=True, \n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # Passa pelas camadas RNN\n",
    "        packed_output, (h_n, _) = rnn(packed_input)\n",
    "        \n",
    "        # h_n tem a forma (num_layers * num_directions, batch, hidden_size)\n",
    "        # Para bidirectional=True, num_directions = 2\n",
    "        # Extraímos os estados ocultos das últimas camadas forward e backward\n",
    "        h_n_forward = h_n[-2, :, :]  # Última camada forward: forma (batch, hidden_size)\n",
    "        h_n_backward = h_n[-1, :, :]  # Última camada backward: forma (batch, hidden_size)\n",
    "        \n",
    "        # Concatena os estados ocultos forward e backward\n",
    "        combined = torch.cat((h_n_forward, h_n_backward), dim=1)  # forma: (batch, hidden_size * 2)\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def forward(self, sequences1, sequences2):\n",
    "        \"\"\"\n",
    "        Forward pass do modelo.\n",
    "\n",
    "        Args:\n",
    "            sequences1 (list of tensors): Primeira lista de sequências de entrada.\n",
    "            sequences2 (list of tensors): Segunda lista de sequências de entrada.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Saída de regressão para cada par de sequências.\n",
    "        \"\"\"\n",
    "        # Processa ambas as sequências usando a função auxiliar\n",
    "        last_output1 = self._process_sequences(sequences1, self.rnn1)  # Forma: (batch, hidden_size * 2)\n",
    "        last_output2 = self._process_sequences(sequences2, self.rnn2)  # Forma: (batch, hidden_size * 2)\n",
    "        \n",
    "        # Concatena as saídas das duas sequências\n",
    "        combined_output = torch.cat((last_output1, last_output2), dim=1)  # Forma: (batch, hidden_size * 4)\n",
    "        \n",
    "        # Passa pela primeira camada totalmente conectada\n",
    "        out = self.fc1(combined_output)  # Forma: (batch, 128)\n",
    "        out = self.relu(out)             # Aplicação da função de ativação\n",
    "        \n",
    "        # Passa pela segunda camada totalmente conectada\n",
    "        out = self.fc2(out)              # Forma: (batch, 1)\n",
    "        \n",
    "        return out.squeeze(1)  # Forma: (batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o modelo, critério de perda e otimizador\n",
    "model_order = RegressionRNN().to('cuda')\n",
    "#criterion = nn.MSELoss() \n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_order.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=3, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o contador de passos\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 01:32:53.062429: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-10 01:32:53.462424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-10 01:32:53.727571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-10 01:32:53.754287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-10 01:32:54.002511: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 01:32:55.489154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Época 480/1000:  48%|████▊     | 479/1000 [9:38:19<10:29:02, 72.44s/época, Perda Treinamento=0.3250, Perda Validação=1.2216, LR=0.000000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model_order\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sequences1_batch, sequences2_batch, targets_batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Transferir dados para GPU\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mSequenceDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#start_time = time.time()\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 21\u001b[0m     sequence1 \u001b[38;5;241m=\u001b[39m text_to_embedding(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m     sequence2 \u001b[38;5;241m=\u001b[39m text_to_embedding(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Use the transformed target\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mtext_to_embedding\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;66;03m# [1,2048] até [1024,2048]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39mcpu()  \u001b[38;5;66;03m# Move para CPU\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inicializar o writer do TensorBoard\n",
    "writer = SummaryWriter('runs/treinamento_regressao_rnn')\n",
    "\n",
    "epoch_progress = tqdm(range(num_epochs), desc='Treinamento', unit='época')\n",
    "for epoch in epoch_progress:\n",
    "    epoch_progress.set_description(f'Época {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    # Treinamento\n",
    "    model_order.train()\n",
    "    train_loss = 0.0\n",
    "    for sequences1_batch, sequences2_batch, targets_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Transferir dados para GPU\n",
    "        sequences1_batch = [seq.to('cuda') for seq in sequences1_batch]\n",
    "        sequences2_batch = [seq.to('cuda') for seq in sequences2_batch]\n",
    "        targets_batch = targets_batch.to('cuda')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_order(sequences1_batch, sequences2_batch)\n",
    "        loss = criterion(outputs, targets_batch)\n",
    "        \n",
    "        # Backward pass e otimização\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Registrar a perda de treinamento a cada passo\n",
    "        writer.add_scalar('Perda_Treinamento_Passo', loss.item(), step)\n",
    "        step += 1\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    \n",
    "    # Validação\n",
    "    model_order.eval()\n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences1_batch, sequences2_batch, targets_batch in validation_dataloader:\n",
    "            sequences1_batch = [seq.to('cuda') for seq in sequences1_batch]\n",
    "            sequences2_batch = [seq.to('cuda') for seq in sequences2_batch]\n",
    "            targets_batch = targets_batch.to('cuda')\n",
    "            \n",
    "            # Forward pass sem autocast\n",
    "            outputs = model_order(sequences1_batch, sequences2_batch)\n",
    "            loss = criterion(outputs, targets_batch)\n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "    avg_validation_loss = validation_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Registrar as métricas de validação por época\n",
    "    writer.add_scalar('Perda_Validação_Epoca', avg_validation_loss, epoch+1)\n",
    "    \n",
    "    # Passar a perda de validação para o scheduler\n",
    "    scheduler.step(avg_validation_loss)\n",
    "    \n",
    "    # Registrar a taxa de aprendizado atual (opcional)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Taxa_Aprendizado', current_lr, epoch+1)\n",
    "    \n",
    "    # Atualizar a descrição da barra com as perdas atuais\n",
    "    epoch_progress.set_postfix({'Perda Treinamento': f'{avg_train_loss:.4f}', \n",
    "                                 'Perda Validação': f'{avg_validation_loss:.4f}',\n",
    "                                 'LR': f'{current_lr:.6f}'})\n",
    "    \n",
    "    # Liberar cache da GPU após cada época\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# Fechar o SummaryWriter ao final do treinamento\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jadson/anaconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:920: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4194304, 1]' is invalid for input of size 1048576",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_order(text_to_embedding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbom dia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m),text_to_embedding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboa noite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 92\u001b[0m, in \u001b[0;36mRegressionRNN.forward\u001b[0;34m(self, sequences1, sequences2)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03mForward pass do modelo.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    Tensor: Saída de regressão para cada par de sequências.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Processa ambas as sequências usando a função auxiliar\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m last_output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_sequences(sequences1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn1)  \u001b[38;5;66;03m# Forma: (batch, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m last_output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_sequences(sequences2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn2)  \u001b[38;5;66;03m# Forma: (batch, hidden_size * 2)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Concatena as saídas das duas sequências\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 67\u001b[0m, in \u001b[0;36mRegressionRNN._process_sequences\u001b[0;34m(self, sequences, rnn)\u001b[0m\n\u001b[1;32m     59\u001b[0m packed_input \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(\n\u001b[1;32m     60\u001b[0m     padded_sequences, \n\u001b[1;32m     61\u001b[0m     lengths\u001b[38;5;241m.\u001b[39mcpu(), \n\u001b[1;32m     62\u001b[0m     batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     63\u001b[0m     enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Passa pelas camadas RNN\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m packed_output, (h_n, _) \u001b[38;5;241m=\u001b[39m rnn(packed_input)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# h_n tem a forma (num_layers * num_directions, batch, hidden_size)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Para bidirectional=True, num_directions = 2\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Extraímos os estados ocultos das últimas camadas forward e backward\u001b[39;00m\n\u001b[1;32m     72\u001b[0m h_n_forward \u001b[38;5;241m=\u001b[39m h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, :, :]  \u001b[38;5;66;03m# Última camada forward: forma (batch, hidden_size)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:920\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    917\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    918\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    921\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n\u001b[1;32m    922\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    923\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4194304, 1]' is invalid for input of size 1048576"
     ]
    }
   ],
   "source": [
    "model_order(text_to_embedding(\"bom dia\").to('cuda'),text_to_embedding(\"boa noite\").to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2048])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_embedding(\"bom dia\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em ./saved_models/regression_rnn_model.pth\n",
      "Estado do otimizador salvo em ./saved_models/optimizer_state.pth\n",
      "Checkpoint salvo em ./saved_models/last_epoch.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Diretório onde os modelos serão salvos\n",
    "save_dir = './saved_models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Salvando o estado do modelo\n",
    "model_path = os.path.join(save_dir, 'regression_rnn_model.pth')\n",
    "torch.save(model_order.state_dict(), model_path)\n",
    "print(f\"Modelo salvo em {model_path}\")\n",
    "\n",
    "# Opcional: Salvando o estado do otimizador\n",
    "optimizer_path = os.path.join(save_dir, 'optimizer_state.pth')\n",
    "torch.save(optimizer.state_dict(), optimizer_path)\n",
    "print(f\"Estado do otimizador salvo em {optimizer_path}\")\n",
    "\n",
    "# Opcional: Salvar a época atual para retomar o treinamento\n",
    "epoch_path = os.path.join(save_dir, 'last_epoch.pth')\n",
    "torch.save({'epoch': epoch, 'model_state_dict': model_order.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_validation_loss}, epoch_path)\n",
    "print(f\"Checkpoint salvo em {epoch_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2268"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_order  # Remove a referência ao modelo\n",
    "\n",
    "# Libera a memória da GPU, se o modelo estiver usando CUDA\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Força a coleta de lixo\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
