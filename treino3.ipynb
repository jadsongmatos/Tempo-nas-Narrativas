{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87469bff7234841aabc42c6071da7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "      <th>target</th>\n",
       "      <th>target_transformed</th>\n",
       "      <th>a_content_length</th>\n",
       "      <th>b_content_length</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1926</td>\n",
       "      <td>1926</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>into their lungs. Special note</td>\n",
       "      <td>-6</td>\n",
       "      <td>-1.945910</td>\n",
       "      <td>1926</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>their lungs. Special note should be taken that...</td>\n",
       "      <td>-11</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>1926</td>\n",
       "      <td>55</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>from their mouth into their lungs. Special not...</td>\n",
       "      <td>11</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1926</td>\n",
       "      <td>992</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>lungs. Special note should be taken that newer...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-2.890372</td>\n",
       "      <td>1926</td>\n",
       "      <td>477</td>\n",
       "      <td>0.999617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208133</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>118</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208134</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208135</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>489</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208136</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>1766</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208137</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>942</td>\n",
       "      <td>0.006028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3208138 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  \\\n",
       "0        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "1        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "2        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "4        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "...                                                    ...   \n",
       "3208133  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208134  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208135  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208136  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208137  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "\n",
       "                                                  content1  \\\n",
       "0        mouth into their lungs. Special note should be...   \n",
       "1        mouth into their lungs. Special note should be...   \n",
       "2        mouth into their lungs. Special note should be...   \n",
       "3        mouth into their lungs. Special note should be...   \n",
       "4        mouth into their lungs. Special note should be...   \n",
       "...                                                    ...   \n",
       "3208133                            Port New 4.02v Firmware   \n",
       "3208134                            Port New 4.02v Firmware   \n",
       "3208135                            Port New 4.02v Firmware   \n",
       "3208136                            Port New 4.02v Firmware   \n",
       "3208137                            Port New 4.02v Firmware   \n",
       "\n",
       "                                                  content2  target  \\\n",
       "0        mouth into their lungs. Special note should be...       0   \n",
       "1                           into their lungs. Special note      -6   \n",
       "2        their lungs. Special note should be taken that...     -11   \n",
       "3        from their mouth into their lungs. Special not...      11   \n",
       "4        lungs. Special note should be taken that newer...     -17   \n",
       "...                                                    ...     ...   \n",
       "3208133  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208134  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208135  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208136  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208137  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "\n",
       "         target_transformed  a_content_length  b_content_length  \\\n",
       "0                  0.000000              1926              1926   \n",
       "1                 -1.945910              1926                30   \n",
       "2                 -2.484907              1926                55   \n",
       "3                  2.484907              1926               992   \n",
       "4                 -2.890372              1926               477   \n",
       "...                     ...               ...               ...   \n",
       "3208133           10.003242                23               118   \n",
       "3208134           10.003242                23                59   \n",
       "3208135           10.003242                23               489   \n",
       "3208136           10.003242                23              1766   \n",
       "3208137           10.003242                23               942   \n",
       "\n",
       "         composite_score  \n",
       "0               1.000000  \n",
       "1               0.999865  \n",
       "2               0.999752  \n",
       "3               0.999752  \n",
       "4               0.999617  \n",
       "...                  ...  \n",
       "3208133         0.006028  \n",
       "3208134         0.006028  \n",
       "3208135         0.006028  \n",
       "3208136         0.006028  \n",
       "3208137         0.006028  \n",
       "\n",
       "[3208138 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "db1_path = 'fineweb.duckdb'\n",
    "db2_path = 'books.duckdb'\n",
    "\n",
    "# Conectar ao banco de dados principal\n",
    "conn = duckdb.connect(database=db1_path, read_only=True)\n",
    "\n",
    "# Anexar o segundo banco de dados\n",
    "conn.execute(f\"ATTACH DATABASE '{db2_path}' AS db2\")\n",
    "\n",
    "# Verificar esquemas (opcional, mas recomendado)\n",
    "schema_main = conn.execute(\"DESCRIBE names\").fetchdf()\n",
    "schema_db2 = conn.execute(f\"DESCRIBE db2.names\").fetchdf()\n",
    "\n",
    "if not schema_main.equals(schema_db2):\n",
    "\traise Exception(\"Os esquemas das tabelas 'names' nos dois bancos de dados nÃ£o sÃ£o compatÃ­veis.\")\n",
    "\n",
    "# Executar a consulta modificada\n",
    "df_training = conn.execute(f\"\"\"\n",
    "WITH combined_name AS (\n",
    "\tSELECT * FROM names\n",
    "\tUNION ALL\n",
    "\tSELECT * FROM db2.names\n",
    "),\n",
    "combined_dataset AS (\n",
    "\tSELECT * FROM dataset_details\n",
    "\tUNION ALL\n",
    "\tSELECT * FROM db2.dataset_details\n",
    "),\n",
    "filter_name AS (\n",
    "    SELECT name_id, name\n",
    "    FROM combined_name\n",
    "    ORDER BY name\n",
    "),\n",
    "sampled_a AS (\n",
    "    SELECT d.*\n",
    "    FROM dataset_details d\n",
    "    JOIN filter_name fn ON fn.name_id = d.name_id\n",
    "\tLIMIT 4000\n",
    "),\n",
    "sampled_b AS (\n",
    "    SELECT d.*\n",
    "    FROM dataset_details d\n",
    "    JOIN filter_name fn ON fn.name_id = d.name_id\n",
    "\tLIMIT 4000\n",
    "),\n",
    "combined AS (\n",
    "    SELECT\n",
    "        fn.name AS name,\n",
    "        a.content AS content1,\n",
    "        b.content AS content2,\n",
    "        a.indice - b.indice AS target,\n",
    "        SIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed,\n",
    "        a.content_length AS a_content_length,  -- Renomeado\n",
    "        b.content_length AS b_content_length   -- Renomeado\n",
    "    FROM sampled_a a\n",
    "    JOIN sampled_b b ON a.name_id = b.name_id\n",
    "    JOIN filter_name fn ON a.name_id = fn.name_id\n",
    "),\n",
    "normalized AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        (a_content_length - MIN(a_content_length) OVER ()) / \n",
    "        NULLIF((MAX(a_content_length) OVER () - MIN(a_content_length) OVER ()), 0) AS normalized_length,        \n",
    "        1 - ((ABS(target) - MIN(ABS(target)) OVER ()) / \n",
    "        NULLIF((MAX(ABS(target)) OVER () - MIN(ABS(target)) OVER ()), 0)) AS normalized_target\n",
    "    FROM combined\n",
    ")\n",
    "SELECT\n",
    "    name,\n",
    "    content1,\n",
    "    content2,\n",
    "    target,\n",
    "    target_transformed,\n",
    "    a_content_length,\n",
    "    b_content_length,\n",
    "    (normalized_length * 0.5 + normalized_target * 0.5) AS composite_score\n",
    "FROM normalized\n",
    "ORDER BY composite_score DESC\n",
    "\"\"\").df()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_training['target_transformed'], bins=50, alpha=0.5, label='target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "      <th>target</th>\n",
       "      <th>target_transformed</th>\n",
       "      <th>a_content_length</th>\n",
       "      <th>b_content_length</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>target_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1926</td>\n",
       "      <td>1926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>into their lungs. Special note</td>\n",
       "      <td>-6</td>\n",
       "      <td>-1.945910</td>\n",
       "      <td>1926</td>\n",
       "      <td>30</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>-0.229805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>their lungs. Special note should be taken that...</td>\n",
       "      <td>-11</td>\n",
       "      <td>-2.484907</td>\n",
       "      <td>1926</td>\n",
       "      <td>55</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>-0.293103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>from their mouth into their lungs. Special not...</td>\n",
       "      <td>11</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>1926</td>\n",
       "      <td>992</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.290530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>mouth into their lungs. Special note should be...</td>\n",
       "      <td>lungs. Special note should be taken that newer...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-2.890372</td>\n",
       "      <td>1926</td>\n",
       "      <td>477</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>-0.340719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208133</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>118</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>1.173449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208134</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>1.173449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208135</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>489</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>1.173449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208136</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>1766</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>1.173449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208137</th>\n",
       "      <td>https://www.zeecigs.com/Black-Genuine-Joyetech...</td>\n",
       "      <td>Port New 4.02v Firmware</td>\n",
       "      <td>18650 Removable Battery Is Sold Separately, pl...</td>\n",
       "      <td>22097</td>\n",
       "      <td>10.003242</td>\n",
       "      <td>23</td>\n",
       "      <td>942</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>1.173449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3208138 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      name  \\\n",
       "0        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "1        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "2        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "4        https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "...                                                    ...   \n",
       "3208133  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208134  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208135  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208136  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "3208137  https://www.zeecigs.com/Black-Genuine-Joyetech...   \n",
       "\n",
       "                                                  content1  \\\n",
       "0        mouth into their lungs. Special note should be...   \n",
       "1        mouth into their lungs. Special note should be...   \n",
       "2        mouth into their lungs. Special note should be...   \n",
       "3        mouth into their lungs. Special note should be...   \n",
       "4        mouth into their lungs. Special note should be...   \n",
       "...                                                    ...   \n",
       "3208133                            Port New 4.02v Firmware   \n",
       "3208134                            Port New 4.02v Firmware   \n",
       "3208135                            Port New 4.02v Firmware   \n",
       "3208136                            Port New 4.02v Firmware   \n",
       "3208137                            Port New 4.02v Firmware   \n",
       "\n",
       "                                                  content2  target  \\\n",
       "0        mouth into their lungs. Special note should be...       0   \n",
       "1                           into their lungs. Special note      -6   \n",
       "2        their lungs. Special note should be taken that...     -11   \n",
       "3        from their mouth into their lungs. Special not...      11   \n",
       "4        lungs. Special note should be taken that newer...     -17   \n",
       "...                                                    ...     ...   \n",
       "3208133  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208134  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208135  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208136  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "3208137  18650 Removable Battery Is Sold Separately, pl...   22097   \n",
       "\n",
       "         target_transformed  a_content_length  b_content_length  \\\n",
       "0                  0.000000              1926              1926   \n",
       "1                 -1.945910              1926                30   \n",
       "2                 -2.484907              1926                55   \n",
       "3                  2.484907              1926               992   \n",
       "4                 -2.890372              1926               477   \n",
       "...                     ...               ...               ...   \n",
       "3208133           10.003242                23               118   \n",
       "3208134           10.003242                23                59   \n",
       "3208135           10.003242                23               489   \n",
       "3208136           10.003242                23              1766   \n",
       "3208137           10.003242                23               942   \n",
       "\n",
       "         composite_score  target_norm  \n",
       "0               1.000000    -0.001286  \n",
       "1               0.999865    -0.229805  \n",
       "2               0.999752    -0.293103  \n",
       "3               0.999752     0.290530  \n",
       "4               0.999617    -0.340719  \n",
       "...                  ...          ...  \n",
       "3208133         0.006028     1.173449  \n",
       "3208134         0.006028     1.173449  \n",
       "3208135         0.006028     1.173449  \n",
       "3208136         0.006028     1.173449  \n",
       "3208137         0.006028     1.173449  \n",
       "\n",
       "[3208138 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Escalonar os dados\n",
    "scaler = StandardScaler()\n",
    "df_training['target_norm'] = scaler.fit_transform(df_training[['target_transformed']])\n",
    "\n",
    "# Salvando o scaler no disco\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "    \n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_training['target_norm'], bins=50, alpha=0.5, label='target')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Converter DataLoader para iterador\n",
    "data_iter = iter(train_dataloader)\n",
    "# Pegar o primeiro lote\n",
    "embeddings, lengths, targets = next(data_iter)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Carregando o scaler novamente\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative_threshold: 0.11614909617348364\n",
      "positive_threshold: -0.11872185475148427\n",
      "Valor revertido: [[1.0], [-1.0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "single_value_df = pd.DataFrame([[1.0],[-1.0]], columns=['target_transformed'])\n",
    "\n",
    "valor_escalonado = scaler.transform(single_value_df)\n",
    "\n",
    "# Definir os limites para considerar positivo ou negativo\n",
    "negative_threshold = valor_escalonado[0][0]\n",
    "positive_threshold = valor_escalonado[1][0]\n",
    "\n",
    "print(\"negative_threshold:\", negative_threshold)\n",
    "print(\"positive_threshold:\", positive_threshold)\n",
    "\n",
    "# Reverter a transformaÃ§Ã£o\n",
    "valor_revertido = scaler.inverse_transform(valor_escalonado)\n",
    "print(\"Valor revertido:\", valor_revertido.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def signed_log_transform(y):\n",
    "    return np.sign(y) * np.log1p(np.abs(y))\n",
    "\n",
    "def inverse_signed_log_transform(y_transformed):\n",
    "    return np.sign(y_transformed) * (np.expm1(np.abs(y_transformed)))\n",
    "\n",
    "def dissimilaridade(S):\n",
    "\tepsilon = 0\n",
    "\tif S == 0:\n",
    "\t\tmax_x = np.log(np.finfo(np.float32).max)\n",
    "\t\tepsilon = (1/(max_x-1))\n",
    "        \n",
    "\treturn (1 - (S+epsilon)) / (S+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÃ©dias: [0.01095392]\n",
      "Desvios PadrÃ£o: [8.51531444]\n",
      "Dados transformados manualmente:\n",
      " [ 0.1161491  -0.00128638 -0.11872185]\n"
     ]
    }
   ],
   "source": [
    "# ObtÃ©m as mÃ©dias das caracterÃ­sticas\n",
    "medias = scaler.mean_\n",
    "print(\"MÃ©dias:\", medias)\n",
    "\n",
    "# ObtÃ©m os desvios padrÃ£o das caracterÃ­sticas\n",
    "desvios_padrao = scaler.scale_\n",
    "print(\"Desvios PadrÃ£o:\", desvios_padrao)\n",
    "\n",
    "# Dados a serem transformados\n",
    "X_novo = np.array([1,0,-1])\n",
    "\n",
    "# Aplicando a transformaÃ§Ã£o manualmente\n",
    "X_transformado = (X_novo - scaler.mean_) / scaler.scale_\n",
    "print(\"Dados transformados manualmente:\\n\", X_transformado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. Please ensure you have a compatible GPU and drivers installed.\")\n",
    "else:\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "\n",
    "# Definir paralelismo corretamente\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "class TextToEmbedding:\n",
    "    def __init__(self, weights_path, num_ids=128256, vector_size=2048, device='cpu'):\n",
    "        \"\"\"\n",
    "        Inicializa a classe TextToEmbedding sem padding fixo.\n",
    "\n",
    "        Args:\n",
    "            weights_path (str): Caminho para o arquivo .npy que contÃ©m os pesos.\n",
    "            num_ids (int, opcional): NÃºmero total de IDs. PadrÃ£o Ã© 128256.\n",
    "            vector_size (int, opcional): Tamanho de cada vetor de embedding. PadrÃ£o Ã© 2048.\n",
    "            device (str, opcional): Dispositivo para carregar os tensores ('cpu' ou 'cuda'). PadrÃ£o Ã© 'cpu'.\n",
    "        \"\"\"\n",
    "\t\t\n",
    "        self.device = device\n",
    "\n",
    "        # Carrega o tokenizer sem padding fixo\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B\", use_fast=True)\n",
    "        \n",
    "        # Carrega os pesos a partir do arquivo .npy\n",
    "        try:\n",
    "            weights_np = np.load(weights_path)\n",
    "            self.weights = torch.from_numpy(weights_np).to(self.device)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"O arquivo de pesos '{weights_path}' nÃ£o foi encontrado.\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Erro ao carregar os pesos: {e}\")\n",
    "        \n",
    "        # Verifica a forma dos pesos\n",
    "        if self.weights.shape != (num_ids, vector_size):\n",
    "            raise ValueError(f\"O formato do arquivo weights.npy Ã© {self.weights.shape}, mas era esperado {(num_ids, vector_size)}.\")\n",
    "\n",
    "embedding_generator = TextToEmbedding(\"weights_half.npy\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class SequenceDataset_val(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "        # Normalizar o target\n",
    "        self.df['target_norm'] = scaler.transform(self.df[['target_transformed']])\n",
    "\n",
    "        # Definir o nÃºmero de elementos originais em cada coluna\n",
    "        num_content1 = len(self.df['content1'])\n",
    "\n",
    "        # Combinar as duas colunas de conteÃºdo em uma lista\n",
    "        contents = list(self.df['content1']) + list(self.df['content2'])\n",
    "\n",
    "        # TokenizaÃ§Ã£o combinada\n",
    "        encoding = embedding_generator.tokenizer(\n",
    "            contents,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,  # Padding dinÃ¢mico\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Separar os encodings de volta para cada conjunto\n",
    "        encoding1 = {key: encoding[key][:num_content1] for key in encoding.keys()}\n",
    "        encoding2 = {key: encoding[key][num_content1:] for key in encoding.keys()}\n",
    "\n",
    "        # Converter para o dispositivo\n",
    "        input_ids1 = encoding1['input_ids'].to(embedding_generator.device)\n",
    "        attention_mask1 = encoding1['attention_mask'].to(embedding_generator.device)\n",
    "        input_ids2 = encoding2['input_ids'].to(embedding_generator.device)\n",
    "        attention_mask2 = encoding2['attention_mask'].to(embedding_generator.device)\n",
    "\n",
    "        # Obter embeddings\n",
    "        embeddings1 = embedding_generator.weights[input_ids1]\n",
    "        embeddings2 = embedding_generator.weights[input_ids2]\n",
    "\n",
    "        # Concatenar as duas sequÃªncias no eixo 1\n",
    "        self.embeddings = torch.stack([embeddings1, embeddings2], dim=1)  # (batch_size, 2, seq_length, vector_size)\n",
    "\n",
    "        # Calcular comprimentos\n",
    "        lengths1 = attention_mask1.sum(dim=1)\n",
    "        lengths2 = attention_mask2.sum(dim=1)\n",
    "        self.lengths = torch.stack([lengths1, lengths2], dim=1)  # (batch_size, 2)\n",
    "\n",
    "        # Calcular comprimento combinado (exemplo: mÃ¡ximo dos dois)\n",
    "        combined_lengths = torch.max(lengths1, lengths2)\n",
    "\n",
    "        # Obter Ã­ndices ordenados em ordem decrescente de comprimento combinado\n",
    "        sorted_idx = combined_lengths.argsort(descending=True)\n",
    "\n",
    "        # Ordenar embeddings, comprimentos e targets\n",
    "        self.embeddings = self.embeddings[sorted_idx]\n",
    "        self.lengths = self.lengths[sorted_idx]\n",
    "        self.targets = torch.tensor(self.df['target_norm'].values, dtype=torch.float16)[sorted_idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.lengths[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import duckdb\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "db1_path = 'fineweb.duckdb'\n",
    "db2_path = 'books.duckdb'\n",
    "batch_size = 10\n",
    "\n",
    "class IterableSequenceDataset(IterableDataset):\n",
    "    def __init__(self, db1_path, db2_path, batch_size):\n",
    "        super(IterableSequenceDataset, self).__init__()\n",
    "        self.db1_path = db1_path\n",
    "        self.db2_path = db2_path\n",
    "        self.batch_size = batch_size\n",
    "        self.offset = 0\n",
    "\n",
    "    def _fetch_data(self, conn):\n",
    "        query = f\"\"\"\n",
    "WITH combined_name AS (\n",
    "\tSELECT * FROM names\n",
    "\tUNION ALL\n",
    "\tSELECT * FROM db2.names\n",
    "),\n",
    "combined_dataset AS (\n",
    "\tSELECT * FROM dataset_details\n",
    "\tUNION ALL\n",
    "\tSELECT * FROM db2.dataset_details\n",
    "),\n",
    "filter_name AS (\n",
    "    SELECT name_id, name\n",
    "    FROM combined_name\n",
    "    ORDER BY name\n",
    "    LIMIT 1 OFFSET {self.offset}\n",
    "),\n",
    "sampled_a AS (\n",
    "    SELECT d.*\n",
    "    FROM dataset_details d\n",
    "    JOIN filter_name fn ON fn.name_id = d.name_id\n",
    "),\n",
    "sampled_b AS (\n",
    "    SELECT d.*\n",
    "    FROM dataset_details d\n",
    "    JOIN filter_name fn ON fn.name_id = d.name_id\n",
    ")\n",
    "SELECT\n",
    "\ta.name_id AS name_id,\n",
    "\ta.content AS content1,\n",
    "\tb.content AS content2,\n",
    "\ta.indice - b.indice AS target,\n",
    "\tSIGN(a.indice - b.indice) * LN(1 + ABS(a.indice - b.indice)) AS target_transformed,\n",
    "\ta.content_length,\n",
    "\tb.content_length\n",
    "FROM sampled_a a\n",
    "JOIN sampled_b b ON a.name_id = b.name_id\n",
    "ORDER BY (a.content_length + b.content_length) DESC\n",
    "LIMIT {self.batch_size};\n",
    "\n",
    "        \"\"\"\n",
    "        df = conn.execute(query).df()\n",
    "        self.offset += 1\n",
    "\n",
    "        if df.empty:\n",
    "            return None, None, None  # Indica que nÃ£o hÃ¡ mais dados\n",
    "\n",
    "        # Normalizar o target\n",
    "        df['target_norm'] = scaler.transform(df[['target_transformed']])\n",
    "\n",
    "        # Defina o nÃºmero de elementos originais em cada coluna\n",
    "        num_content1 = len(df['content1'])\n",
    "\n",
    "        # Combinar as duas colunas de conteÃºdo em uma lista\n",
    "        contents = list(df['content1']) + list(df['content2'])\n",
    "\n",
    "        # TokenizaÃ§Ã£o combinada\n",
    "        encoding = embedding_generator.tokenizer(\n",
    "            contents,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,  # Padding dinÃ¢mico\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Separar os encodings de volta para cada conjunto\n",
    "        encoding1 = {key: encoding[key][:num_content1] for key in encoding.keys()}\n",
    "        encoding2 = {key: encoding[key][num_content1:] for key in encoding.keys()}\n",
    "\n",
    "        # Converter para o dispositivo\n",
    "        input_ids1 = encoding1['input_ids'].to(embedding_generator.device)\n",
    "        attention_mask1 = encoding1['attention_mask'].to(embedding_generator.device)\n",
    "        input_ids2 = encoding2['input_ids'].to(embedding_generator.device)\n",
    "        attention_mask2 = encoding2['attention_mask'].to(embedding_generator.device)\n",
    "\n",
    "        # Obter embeddings\n",
    "        embeddings1 = embedding_generator.weights[input_ids1]\n",
    "        embeddings2 = embedding_generator.weights[input_ids2]\n",
    "\n",
    "        # Concatenar as duas sequÃªncias no eixo 1\n",
    "        embeddings = torch.stack([embeddings1, embeddings2], dim=1)  # (batch_size, 2, seq_length, vector_size)\n",
    "\n",
    "        # Calcular comprimentos\n",
    "        lengths1 = attention_mask1.sum(dim=1)\n",
    "        lengths2 = attention_mask2.sum(dim=1)\n",
    "        lengths = torch.stack([lengths1, lengths2], dim=1)  # (batch_size, 2)\n",
    "\n",
    "        # Calcular comprimento combinado (mÃ¡ximo dos dois)\n",
    "        combined_lengths = torch.max(lengths1, lengths2)\n",
    "\n",
    "        # Obter Ã­ndices ordenados em ordem decrescente de comprimento combinado\n",
    "        sorted_idx = combined_lengths.argsort(descending=True)\n",
    "\n",
    "        # Ordenar embeddings, comprimentos e targets\n",
    "        embeddings = embeddings[sorted_idx]\n",
    "        lengths = lengths[sorted_idx]\n",
    "        targets = torch.tensor(df['target_norm'].values, dtype=torch.float16)[sorted_idx]\n",
    "\n",
    "        return embeddings, lengths, targets\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterator que gera dados continuamente.\n",
    "\n",
    "        Yields:\n",
    "            tuple: (embeddings, lengths, targets) para cada amostra.\n",
    "        \"\"\"\n",
    "        # Estabelecer conexÃ£o com DuckDB\n",
    "        conn = duckdb.connect(database=self.db1_path, read_only=True)\n",
    "        conn.execute(\"SET enable_progress_bar=false\")\n",
    "\n",
    "        # Anexar o segundo banco de dados com um alias 'db2'\n",
    "        conn.execute(f\"ATTACH '{self.db2_path}' AS db2\")\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                embeddings, lengths, targets = self._fetch_data(conn)\n",
    "                if embeddings is None:\n",
    "                    break  # Termina a iteraÃ§Ã£o se nÃ£o houver mais dados\n",
    "\n",
    "                for i in range(embeddings.size(0)):\n",
    "                    yield embeddings[i], lengths[i], targets[i]\n",
    "        finally:\n",
    "            # Garantir que a conexÃ£o seja fechada quando o iterador for finalizado\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_transformed</th>\n",
       "      <th>content1</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>A tempestade durou vÃ¡rias horas durante a noite.</td>\n",
       "      <td>A tempestade durou vÃ¡rias horas durante a noite.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Ele estudou intensamente para o exame.</td>\n",
       "      <td>Ele estudou intensamente para o exame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>A fÃ¡brica reduziu a emissÃ£o de poluentes.</td>\n",
       "      <td>A fÃ¡brica reduziu a emissÃ£o de poluentes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Maria comeÃ§ou a praticar exercÃ­cios regularmente.</td>\n",
       "      <td>Maria comeÃ§ou a praticar exercÃ­cios regularmente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>O motor do carro parou de funcionar.</td>\n",
       "      <td>O motor do carro parou de funcionar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>Isso resultou na reduÃ§Ã£o significativa das emi...</td>\n",
       "      <td>ApÃ³s anos de pesquisa e desenvolvimento, a equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>Ela sentiu fome e falta de energia durante a m...</td>\n",
       "      <td>O cafÃ© da manhÃ£ foi esquecido.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>As praias ficaram mais limpas e atraentes para...</td>\n",
       "      <td>A iniciativa comunitÃ¡ria organizou mutirÃµes de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>Finalmente recebeu uma oferta de trabalho em u...</td>\n",
       "      <td>Ele atualizou seu currÃ­culo e participou de vÃ¡...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.693147</td>\n",
       "      <td>Suas peÃ§as ganharam destaque em exposiÃ§Ãµes int...</td>\n",
       "      <td>O artista decidiu experimentar novas tÃ©cnicas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_transformed                                           content1  \\\n",
       "0              0.000000   A tempestade durou vÃ¡rias horas durante a noite.   \n",
       "1              0.000000             Ele estudou intensamente para o exame.   \n",
       "2              0.000000          A fÃ¡brica reduziu a emissÃ£o de poluentes.   \n",
       "3              0.000000  Maria comeÃ§ou a praticar exercÃ­cios regularmente.   \n",
       "4              0.000000               O motor do carro parou de funcionar.   \n",
       "..                  ...                                                ...   \n",
       "145           -0.693147  Isso resultou na reduÃ§Ã£o significativa das emi...   \n",
       "146           -0.693147  Ela sentiu fome e falta de energia durante a m...   \n",
       "147           -0.693147  As praias ficaram mais limpas e atraentes para...   \n",
       "148           -0.693147  Finalmente recebeu uma oferta de trabalho em u...   \n",
       "149           -0.693147  Suas peÃ§as ganharam destaque em exposiÃ§Ãµes int...   \n",
       "\n",
       "                                              content2  \n",
       "0     A tempestade durou vÃ¡rias horas durante a noite.  \n",
       "1               Ele estudou intensamente para o exame.  \n",
       "2            A fÃ¡brica reduziu a emissÃ£o de poluentes.  \n",
       "3    Maria comeÃ§ou a praticar exercÃ­cios regularmente.  \n",
       "4                 O motor do carro parou de funcionar.  \n",
       "..                                                 ...  \n",
       "145  ApÃ³s anos de pesquisa e desenvolvimento, a equ...  \n",
       "146                     O cafÃ© da manhÃ£ foi esquecido.  \n",
       "147  A iniciativa comunitÃ¡ria organizou mutirÃµes de...  \n",
       "148  Ele atualizou seu currÃ­culo e participou de vÃ¡...  \n",
       "149  O artista decidiu experimentar novas tÃ©cnicas ...  \n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'target_transformed': [signed_log_transform(1)]*50,\n",
    "    \"content1\": [\"A tempestade durou vÃ¡rias horas durante a noite.\", \"Ele estudou intensamente para o exame.\", \"A fÃ¡brica reduziu a emissÃ£o de poluentes.\", \"Maria comeÃ§ou a praticar exercÃ­cios regularmente.\", \"O motor do carro parou de funcionar.\", \"Houve uma forte seca na regiÃ£o.\", \"Ela comeÃ§ou a dormir melhor.\", \"A escola adotou uma alimentaÃ§Ã£o saudÃ¡vel.\", \"O projeto teve apoio governamental.\", \"A internet caiu durante a reuniÃ£o.\", \"Ele comeÃ§ou a economizar dinheiro mensalmente.\", \"A estrada estava em pÃ©ssimo estado de conservaÃ§Ã£o.\", \"O sistema de ar condicionado foi desligado no escritÃ³rio.\", \"A empresa investiu em marketing digital.\", \"Ana nÃ£o revisou o relatÃ³rio antes de enviar.\", \"As crianÃ§as brincaram no parque atÃ© tarde.\", \"O curso de capacitaÃ§Ã£o foi oferecido aos funcionÃ¡rios.\", \"Ele comprou um celular novo com cÃ¢mera de alta qualidade.\", \"A reforma no prÃ©dio foi concluÃ­da.\", \"A regiÃ£o teve um crescimento populacional rÃ¡pido.\", \"Carla comeÃ§ou a meditar diariamente.\", \"O atleta intensificou seu treino antes da competiÃ§Ã£o.\", \"O sinal de celular na regiÃ£o foi ampliado.\", \"As temperaturas caÃ­ram drasticamente durante o inverno.\", \"Ele nÃ£o configurou o alarme antes de dormir.\", \"A empresa ofereceu benefÃ­cios extras para seus funcionÃ¡rios.\", \"Houve um vazamento de gÃ¡s na cozinha do restaurante.\", \"A biblioteca da escola foi modernizada com novos livros e tecnologia.\", \"Marcos passou a fazer pausas regulares durante o expediente.\", \"A empresa desenvolveu um aplicativo intuitivo para clientes.\", \"Devido ao aumento das chuvas nas Ãºltimas semanas, o nÃ­vel dos rios subiu rapidamente e ultrapassou a capacidade das barragens.\", \"Ela decidiu comeÃ§ar uma rotina de alimentaÃ§Ã£o balanceada, exercÃ­cios fÃ­sicos regulares e meditaÃ§Ã£o diÃ¡ria para melhorar sua saÃºde fÃ­sica e mental.\", \"A empresa, que sofria com baixos Ã­ndices de produtividade, implementou uma nova estratÃ©gia de gestÃ£o focada no desenvolvimento dos funcionÃ¡rios e na cultura organizacional.\", \"O governo lanÃ§ou um programa nacional de reciclagem e incentivou a participaÃ§Ã£o ativa dos cidadÃ£os por meio de campanhas de conscientizaÃ§Ã£o em escolas, empresas e residÃªncias.\", \"ApÃ³s uma longa estiagem que afetou grande parte do territÃ³rio agrÃ­cola do paÃ­s, o governo implementou um pacote emergencial de apoio aos agricultores, incluindo subsÃ­dios e incentivos para a recuperaÃ§Ã£o das lavouras.\", \"Ele deixou o celular carregando a noite inteira sem usar carregadores de seguranÃ§a e em um local sem ventilaÃ§Ã£o.\", \"A comunidade local se uniu para limpar e revitalizar a praÃ§a abandonada, que estava sem manutenÃ§Ã£o hÃ¡ anos e havia se tornado um ponto de descarte irregular de lixo.\", \"Durante a reforma do prÃ©dio, descobriu-se que a estrutura tinha falhas graves, e o prazo para conclusÃ£o foi ampliado em seis meses para garantir a seguranÃ§a.\", \"Um furacÃ£o atingiu a regiÃ£o costeira do paÃ­s, com ventos de mais de 200 km/h, causando destruiÃ§Ã£o em vÃ¡rias cidades e deixando milhares de pessoas desabrigadas.\", \"Ela esqueceu de regar a planta de sua varanda durante o mÃªs todo, e o clima estava seco.\", \"JoÃ£o quebrou o braÃ§o jogando futebol.\", \"Devido a uma combinaÃ§Ã£o de fatores climÃ¡ticos extremos, incluindo ventos fortes e chuvas intensas, a regiÃ£o sofreu graves danos estruturais e interrupÃ§Ã£o no fornecimento de energia elÃ©trica por vÃ¡rios dias.\", \"Ela esqueceu de levar o guarda-chuva.\", \"A empresa adotou prÃ¡ticas sustentÃ¡veis em sua produÃ§Ã£o, reduzindo o uso de plÃ¡stico e implementando programas de reciclagem.\", \"A crianÃ§a se recusou a comer legumes durante toda a semana.\", \"ApÃ³s anos de pesquisa e desenvolvimento, a equipe cientÃ­fica finalmente descobriu um mÃ©todo eficiente para produzir energia limpa a partir de fontes renovÃ¡veis.\", \"O cafÃ© da manhÃ£ foi esquecido.\", \"A iniciativa comunitÃ¡ria organizou mutirÃµes de limpeza nas praias locais regularmente durante o verÃ£o.\", \"Ele atualizou seu currÃ­culo e participou de vÃ¡rias entrevistas de emprego nos Ãºltimos meses.\", \"O artista decidiu experimentar novas tÃ©cnicas em suas pinturas, incorporando elementos digitais e materiais reciclados em suas obras.\"],\n",
    "    \"content2\": [\"Pela manhÃ£, muitas ruas estavam alagadas.\", \"Conseguiu uma nota alta na prova.\", \"A qualidade do ar na cidade melhorou.\", \"Ela perdeu peso e aumentou sua energia.\", \"Ele teve que chamar o guincho para levar o carro Ã  oficina.\", \"As plantaÃ§Ãµes foram prejudicadas, e a colheita foi menor.\", \"Sua disposiÃ§Ã£o durante o dia melhorou significativamente.\", \"Os alunos passaram a ter mais energia e melhor concentraÃ§Ã£o.\", \"Conseguiu concluir as fases iniciais rapidamente.\", \"A comunicaÃ§Ã£o com a equipe foi interrompida.\", \"Conseguiu juntar uma quantia para uma viagem.\", \"O trÃ¢nsito ficou mais lento e perigoso para os motoristas.\", \"O ambiente ficou quente e desconfortÃ¡vel para os funcionÃ¡rios.\", \"As vendas aumentaram significativamente.\", \"O documento continha erros e precisou ser corrigido.\", \"Elas ficaram cansadas e dormiram rapidamente ao chegar em casa.\", \"Eles melhoraram suas habilidades e eficiÃªncia no trabalho.\", \"Passou a tirar fotos mais nÃ­tidas e de melhor resoluÃ§Ã£o.\", \"O local ficou mais seguro e esteticamente agradÃ¡vel.\", \"A demanda por moradias e serviÃ§os aumentou consideravelmente.\", \"Ela sentiu uma melhora no seu foco e reduÃ§Ã£o do estresse.\", \"Teve um melhor desempenho e conquistou o primeiro lugar.\", \"A conexÃ£o ficou mais estÃ¡vel e acessÃ­vel para os moradores.\", \"A procura por agasalhos e cobertores aumentou nas lojas.\", \"Acabou se atrasando para o trabalho na manhÃ£ seguinte.\", \"A satisfaÃ§Ã£o e motivaÃ§Ã£o dos colaboradores aumentaram.\", \"O local foi evacuado por seguranÃ§a, e o serviÃ§o foi interrompido temporariamente.\", \"Os alunos comeÃ§aram a frequentÃ¡-la mais e a melhorar seu desempenho acadÃªmico.\", \"Ele se sentiu mais produtivo e menos cansado ao final do dia.\", \"O nÃºmero de usuÃ¡rios aumentou rapidamente.\", \"Diversas Ã¡reas urbanas e rurais foram afetadas por inundaÃ§Ãµes, forÃ§ando muitas famÃ­lias a deixarem suas casas temporariamente.\", \"Em poucos meses, notou uma grande melhora em sua disposiÃ§Ã£o, concentraÃ§Ã£o e nÃ­veis de energia, alÃ©m de perder peso.\", \"Em menos de um ano, a moral da equipe melhorou, a rotatividade diminuiu, e a produtividade geral aumentou em cerca de 30%.\", \"Como resultado, houve uma reduÃ§Ã£o significativa na quantidade de resÃ­duos sÃ³lidos em aterros e uma maior economia de recursos naturais.\", \"Em um ano, a produÃ§Ã£o agrÃ­cola voltou a nÃ­veis estÃ¡veis, e o impacto econÃ´mico negativo foi mitigado, beneficiando a populaÃ§Ã£o.\", \"Pela manhÃ£, o dispositivo estava superaquecido e apresentou danos permanentes na bateria, reduzindo sua capacidade de funcionamento.\", \"Com a revitalizaÃ§Ã£o, a praÃ§a voltou a ser um local de encontro para moradores, e a seguranÃ§a da Ã¡rea tambÃ©m melhorou.\", \"Apesar do atraso, a reforma resultou em um edifÃ­cio mais seguro, confortÃ¡vel e com um aumento significativo no valor do imÃ³vel.\", \"A resposta emergencial foi mobilizada rapidamente, com abrigos temporÃ¡rios e ajuda humanitÃ¡ria distribuÃ­da para minimizar o impacto nas vÃ­timas.\", \"A planta murchou completamente e, infelizmente, nÃ£o conseguiu ser recuperada, tendo que ser substituÃ­da.\", \"Ele ficou impossibilitado de trabalhar por duas semanas.\", \"A comunidade teve que recorrer a abrigos temporÃ¡rios, e a economia local sofreu uma queda significativa devido Ã  paralisaÃ§Ã£o das atividades comerciais.\", \"Ficou molhada durante o trajeto para o trabalho.\", \"A reputaÃ§Ã£o da empresa melhorou, atraindo consumidores conscientes e aumentando as vendas em 20%.\", \"Sua mÃ£e ficou preocupada com a falta de nutrientes na alimentaÃ§Ã£o dele e decidiu consultar um nutricionista.\", \"Isso resultou na reduÃ§Ã£o significativa das emissÃµes de carbono e no avanÃ§o tecnolÃ³gico sustentÃ¡vel, beneficiando o meio ambiente globalmente.\", \"Ela sentiu fome e falta de energia durante a manhÃ£ de trabalho.\", \"As praias ficaram mais limpas e atraentes para turistas, alÃ©m de promover a conscientizaÃ§Ã£o ambiental entre os moradores.\", \"Finalmente recebeu uma oferta de trabalho em uma empresa renomada, melhorando sua estabilidade financeira.\", \"Suas peÃ§as ganharam destaque em exposiÃ§Ãµes internacionais, ampliando seu reconhecimento e alcance no mercado de arte.\"]\n",
    "}\n",
    "\n",
    "# Crie o DataFrame\n",
    "df_validation = pd.DataFrame(data)\n",
    "\n",
    "# Adicionar frases iguais\n",
    "df_zero = pd.DataFrame({\n",
    "    'target_transformed': [0] * len(data['target_transformed']),\n",
    "    'content1': df_validation['content1'],\n",
    "    'content2': df_validation['content1']\n",
    "})\n",
    "\n",
    "# Adicionar frases com a ordem contrÃ¡ria\n",
    "df_reversed = pd.DataFrame({\n",
    "    'target_transformed': [signed_log_transform(-1)] * len(data['target_transformed']),\n",
    "    'content1': df_validation['content2'],\n",
    "    'content2': df_validation['content1']\n",
    "})\n",
    "\n",
    "# Concatenar os dois DataFrames\n",
    "df_validation = pd.concat([df_zero, df_validation, df_reversed], ignore_index=True)\n",
    "\n",
    "df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    embeddings, lengths, targets = zip(*batch)\n",
    "    return torch.stack(embeddings).to(torch.float32), torch.stack(lengths), torch.stack(targets).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = IterableSequenceDataset(db1_path, db2_path,batch_size)\n",
    "train_dataloader = DataLoader(\n",
    "  training_dataset, \n",
    "  batch_size=batch_size, \n",
    "  num_workers=0,\n",
    "  collate_fn=collate_fn,\n",
    "  pin_memory=False,\n",
    "  shuffle=False,\n",
    "  #persistent_workers=True\n",
    ")\n",
    "\n",
    "validation_dataset = SequenceDataset_val(df_validation)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=150,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "class SequenceEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        Inicializa o SequenceEncoder.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): DimensÃ£o da entrada de cada elemento da sequÃªncia.\n",
    "            hidden_size (int): Tamanho do estado oculto do LSTM.\n",
    "            num_layers (int): NÃºmero de camadas do LSTM.\n",
    "        \"\"\"\n",
    "        super(SequenceEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.3,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "    def forward(self, sequences, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass do SequenceEncoder.\n",
    "\n",
    "        Args:\n",
    "            sequences (Tensor): Tensor de sequÃªncias com forma [batch_size, seq_len, input_size].\n",
    "            lengths (Tensor): Tensor de comprimentos com forma [batch_size].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: RepresentaÃ§Ã£o codificada das sequÃªncias com forma [batch_size, hidden_size * num_directions].\n",
    "        \"\"\"\n",
    "        # Empacotar as sequÃªncias sem exigir ordenaÃ§Ã£o\n",
    "        packed_seq = rnn_utils.pack_padded_sequence(\n",
    "            sequences,\n",
    "            lengths.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False  # Permite sequÃªncias nÃ£o ordenadas\n",
    "        )\n",
    "\n",
    "        # Passar pelo LSTM\n",
    "        packed_output, (hn, cn) = self.lstm(packed_seq)\n",
    "\n",
    "        hn = hn[-1]  # Forma: [batch_size, hidden_size]\n",
    "\n",
    "        return hn  # [batch_size, hidden_size * num_directions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        Inicializa o SiameseModel.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): DimensÃ£o da entrada de cada elemento da sequÃªncia.\n",
    "            hidden_size (int): Tamanho do estado oculto do LSTM.\n",
    "            num_layers (int): NÃºmero de camadas do LSTM.\n",
    "        \"\"\"\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.encoder = SequenceEncoder(input_size, hidden_size, num_layers)\n",
    "\n",
    "        # Camada totalmente conectada para combinar as duas representaÃ§Ãµes\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # SaÃ­da um Ãºnico valor (e.g., score de similaridade)\n",
    "\n",
    "    def forward(self, sequences, lengths):\n",
    "        \"\"\"\n",
    "        Forward pass para a rede Siamese.\n",
    "\n",
    "        Args:\n",
    "            sequences (Tensor): Tensor de embeddings com forma [batch_size, 2, seq_len, input_size].\n",
    "            lengths (Tensor): Tensor de comprimentos com forma [batch_size, 2].\n",
    "\n",
    "        Returns:\n",
    "            Tensor: PrediÃ§Ãµes de saÃ­da com forma [batch_size].\n",
    "        \"\"\"\n",
    "        # Debug: imprimir formas dos tensores de entrada\n",
    "        # print(f\"sequences shape: {sequences.shape}\")  # [batch_size, 2, seq_len, input_size]\n",
    "        # print(f\"lengths shape: {lengths.shape}\")      # [batch_size, 2]\n",
    "\n",
    "        # Dividir as sequÃªncias e os comprimentos para ambos os inputs\n",
    "        seq1 = sequences[:, 0, :, :]  # Forma: [batch_size, seq_len, input_size]\n",
    "        len1 = lengths[:, 0]           # Forma: [batch_size]\n",
    "        out1 = self.encoder(seq1, len1)  # Forma: [batch_size, hidden_size * num_directions]\n",
    "        \n",
    "        del seq1, len1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        seq2 = sequences[:, 1, :, :]  # Forma: [batch_size, seq_len, input_size]\n",
    "        len2 = lengths[:, 1]           # Forma: [batch_size]\n",
    "        out2 = self.encoder(seq2, len2)  # Forma: [batch_size, hidden_size * num_directions]\n",
    "\n",
    "        del seq2, len2\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Combinar as duas representaÃ§Ãµes\n",
    "        combined = torch.cat([out1, out2], dim=1)  # Forma: [batch_size, hidden_size * num_directions * 2]\n",
    "\n",
    "        # Passar pela camada totalmente conectada\n",
    "        out = self.fc(combined)  # Forma: [batch_size, 1]\n",
    "\n",
    "        return out.squeeze(1)  # Forma: [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "limit_train_batches=20\n",
    "max_epochs=2000\n",
    "\n",
    "class CustomHuberLoss(nn.Module):\n",
    "\tdef __init__(self, delta=1.0):\n",
    "\t\tsuper(CustomHuberLoss, self).__init__()\n",
    "\t\tself.delta = delta\n",
    "\t\tself.huber_loss = nn.HuberLoss(delta=delta)\n",
    "\n",
    "\tdef forward(self, output, target):\n",
    "\t\t# Verificar os sinais de output e target usando os limites fornecidos\n",
    "\t\toutput_sign = (output <= negative_threshold).float() - (output >= positive_threshold).float()\n",
    "\t\ttarget_sign = (target <= negative_threshold).float() - (target >= positive_threshold).float()\n",
    "\n",
    "\t\t# Calcular a perda Huber normal\n",
    "\t\tloss = self.huber_loss(output, target)\n",
    "\n",
    "\t\t# Verificar se o sinal de output Ã© diferente de target\n",
    "\t\tsign_diff = (output_sign != target_sign).float()\n",
    "\n",
    "\t\t# Se os sinais forem diferentes, multiplicar a perda por 2\n",
    "\t\tadjusted_loss = loss * (1 + sign_diff) \n",
    "\n",
    "\t\treturn adjusted_loss.mean()\n",
    "\n",
    "class SiameseModel_Lightning(pl.LightningModule):\n",
    "\tdef __init__(self, input_size=2048, hidden_size=128, num_layers=4, lr=1e-3, max_lr=1e-2):\n",
    "\t\tsuper(SiameseModel_Lightning, self).__init__()\n",
    "\t\tself.save_hyperparameters()\n",
    "\n",
    "\t\t# Instanciar o modelo modificado\n",
    "\t\tself.model = SiameseModel(\n",
    "\t\t\tinput_size=input_size,\n",
    "\t\t\thidden_size=hidden_size,\n",
    "\t\t\tnum_layers=num_layers\n",
    "\t\t)\n",
    "\n",
    "\t\t# FunÃ§Ã£o de perda\n",
    "\t\tself.criterion = CustomHuberLoss()\n",
    "\n",
    "\tdef forward(self, sequences, lengths):\n",
    "\t\treturn self.model(sequences, lengths)\n",
    "\t\n",
    "\tdef training_step(self, batch):\n",
    "\t\tembeddings, lengths, targets = batch  # embeddings: (batch_size, 2, seq_len, vector_size)\n",
    "\t\tembeddings = embeddings.to(self.device)\n",
    "\t\tlengths = lengths.to(self.device)\n",
    "\t\ttargets = targets.to(self.device)\n",
    "\n",
    "\t\t# Passagem para frente\n",
    "\t\toutputs = self(embeddings, lengths)  # (batch_size,)\n",
    "\n",
    "\t\t# Computar a perda\n",
    "\t\tloss = self.criterion(outputs, targets)\n",
    "\n",
    "\t\t# Logar a perda de treinamento\n",
    "\t\tself.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\t\t# Obter a taxa de aprendizado atual do primeiro grupo de parÃ¢metros\n",
    "\t\tlr = self.optimizers().param_groups[0]['lr']\n",
    "\t\t# Logar a taxa de aprendizado\n",
    "\t\tself.log('lr', lr, on_step=True, on_epoch=False, prog_bar=True, logger=True)\n",
    "\n",
    "\t\t# Clear variables\n",
    "\t\tdel embeddings, lengths, targets, outputs\n",
    "\t\tgc.collect()\n",
    "\t\ttorch.cuda.empty_cache()\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef validation_step(self, batch):\n",
    "\t\tembeddings, lengths, targets = batch\n",
    "\t\tembeddings = embeddings.to(self.device)\n",
    "\t\tlengths = lengths.to(self.device)\n",
    "\t\ttargets = targets.to(self.device)\n",
    "\n",
    "\t\t# Passagem para frente\n",
    "\t\toutputs = self(embeddings, lengths)\n",
    "\n",
    "\t\t# Computar a perda\n",
    "\t\tloss = self.criterion(outputs, targets)\n",
    "\n",
    "\t\t# Logar a perda de validaÃ§Ã£o\n",
    "\t\tself.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\t# Otimizador Adam\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "\n",
    "\t\t# ConfiguraÃ§Ã£o do OneCycleLR\n",
    "\t\tscheduler = OneCycleLR(\n",
    "\t\t\toptimizer,\n",
    "\t\t\tmax_lr=self.hparams.max_lr,\n",
    "\t\t\ttotal_steps=(max_epochs * limit_train_batches),\n",
    "\t\t\tanneal_strategy='cos',\n",
    "\t\t\tpct_start=0.3,\n",
    "\t\t\tcycle_momentum=True,\n",
    "\t\t\tbase_momentum=0.85,\n",
    "\t\t\tmax_momentum=0.95,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Retornar otimizador e scheduler com interval definido para 'step'\n",
    "\t\treturn {\n",
    "\t\t\t'optimizer': optimizer,\n",
    "\t\t\t'lr_scheduler': {\n",
    "\t\t\t\t'scheduler': scheduler,\n",
    "\t\t\t\t'interval': 'step',      # Atualiza a cada passo\n",
    "\t\t\t\t'frequency': 1,          # FrequÃªncia de atualizaÃ§Ã£o\n",
    "\t\t\t}\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# Instanciando o TensorBoardLogger\n",
    "tensorboard_logger = TensorBoardLogger('tb_logs', name='model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseModel_Lightning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jadson/anaconda3/envs/pytorch/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/jadson/anaconda3/envs/pytorch/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/jadson/Documentos/Tempo-nas-Narrativas/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type            | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model     | SiameseModel    | 1.6 M  | train\n",
      "1 | criterion | CustomHuberLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.292     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cfe24d0ae64ffc944e599db4553735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jadson/anaconda3/envs/pytorch/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n",
      "/home/jadson/anaconda3/envs/pytorch/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182afc8314844a629b7c4654e31039d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Definir callbacks, por exemplo, ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    precision=16,\n",
    "    gradient_clip_val=1.0,\n",
    "    accelerator='auto',\n",
    "    devices='auto',\n",
    "    callbacks=[checkpoint_callback],\n",
    "    accumulate_grad_batches=20,\n",
    "    deterministic=False,\n",
    "    limit_train_batches=limit_train_batches,\n",
    "    log_every_n_steps=limit_train_batches,\n",
    "    profiler=\"simple\",\n",
    "    logger=tensorboard_logger\n",
    ")\n",
    "\n",
    "# Iniciar o treinamento\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader, #IterableDataset\n",
    "    val_dataloaders=validation_dataloader #Dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o checkpoint salvo\n",
    "caminho_checkpoint = 'checkpoints/best-checkpoint-v9.ckpt'\n",
    "\n",
    "# Carregar o modelo a partir do checkpoint\n",
    "model = SiameseModel_Lightning.load_from_checkpoint(caminho_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_dataloader torch.Size([150, 2, 61, 2048]) torch.Size([150, 2]) torch.Size([150])\n",
      "AcurÃ¡cia: 0.8667\n",
      "Par 1: -0.0354 Target: -0.0000\n",
      "Par 2: -1.6072 Target: 1.0000\n",
      "Par 3: 1.3695 Target: -0.9995\n",
      "Par 4: -0.0639 Target: -0.0000\n",
      "Par 5: -2.8749 Target: 1.0000\n",
      "Par 6: 2.7191 Target: -0.9995\n",
      "Par 7: -2.8562 Target: 1.0000\n",
      "Par 8: -0.0640 Target: -0.0000\n",
      "Par 9: 2.6984 Target: -0.9995\n",
      "Par 10: -0.0641 Target: -0.0000\n",
      "Par 11: 2.6943 Target: -0.9995\n",
      "Par 12: -2.8569 Target: 1.0000\n",
      "Par 13: 2.5854 Target: -0.9995\n",
      "Par 14: 2.6727 Target: -0.9995\n",
      "Par 15: -0.0639 Target: -0.0000\n",
      "Par 16: -2.8290 Target: 1.0000\n",
      "Par 17: -0.0640 Target: -0.0000\n",
      "Par 18: -2.7549 Target: 1.0000\n",
      "Par 19: 2.4161 Target: -0.9995\n",
      "Par 20: -0.0640 Target: -0.0000\n",
      "Par 21: -2.7155 Target: 1.0000\n",
      "Par 22: 0.0315 Target: 1.0000\n",
      "Par 23: 0.0205 Target: -0.0000\n",
      "Par 24: 0.0207 Target: -0.0000\n",
      "Par 25: 0.0055 Target: -0.9995\n",
      "Par 26: -1.7665 Target: 1.0000\n",
      "Par 27: 2.1391 Target: -0.9995\n",
      "Par 28: -0.0069 Target: 1.0000\n",
      "Par 29: 0.0445 Target: -0.9995\n",
      "Par 30: -7.6025 Target: 1.0000\n",
      "Par 31: 0.0164 Target: -0.0000\n",
      "Par 32: 0.0161 Target: -0.0000\n",
      "Par 33: 8.6583 Target: -0.9995\n",
      "Par 34: 2.2667 Target: 1.0000\n",
      "Par 35: -1.9061 Target: -0.9995\n",
      "Par 36: 0.0220 Target: 1.0000\n",
      "Par 37: -0.0014 Target: -0.0000\n",
      "Par 38: -0.0270 Target: -0.9995\n",
      "Par 39: -7.4864 Target: -0.9995\n",
      "Par 40: 8.1967 Target: 1.0000\n",
      "Par 41: 0.1119 Target: -0.0000\n",
      "Par 42: 0.1046 Target: 1.0000\n",
      "Par 43: 0.1046 Target: -0.9995\n",
      "Par 44: 0.1046 Target: -0.0000\n",
      "Par 45: 0.1046 Target: -0.0000\n",
      "Par 46: 0.1051 Target: -0.9995\n",
      "Par 47: 0.1041 Target: 1.0000\n",
      "Par 48: 0.1046 Target: -0.9995\n",
      "Par 49: 0.1046 Target: 1.0000\n",
      "Par 50: 0.1046 Target: -0.0000\n",
      "Par 51: 0.1048 Target: -0.9995\n",
      "Par 52: 0.1051 Target: -0.9995\n",
      "Par 53: 0.1040 Target: 1.0000\n",
      "Par 54: 0.1044 Target: 1.0000\n",
      "Par 55: 0.1036 Target: 1.0000\n",
      "Par 56: 0.1073 Target: -0.9995\n",
      "Par 57: 0.1014 Target: 1.0000\n",
      "Par 58: 0.1055 Target: -0.9995\n",
      "Par 59: 0.1025 Target: 1.0000\n",
      "Par 60: 0.1064 Target: -0.9995\n",
      "Par 61: 0.1064 Target: -0.9995\n",
      "Par 62: 0.1025 Target: 1.0000\n",
      "Par 63: 0.1046 Target: -0.0000\n",
      "Par 64: 0.1050 Target: -0.9995\n",
      "Par 65: 0.1050 Target: -0.9995\n",
      "Par 66: 0.1033 Target: 1.0000\n",
      "Par 67: 0.1041 Target: 1.0000\n",
      "Par 68: 0.1050 Target: -0.9995\n",
      "Par 69: 0.1057 Target: -0.9995\n",
      "Par 70: 0.1041 Target: 1.0000\n",
      "Par 71: 0.1041 Target: 1.0000\n",
      "Par 72: 0.1033 Target: 1.0000\n",
      "Par 73: 0.1057 Target: -0.9995\n",
      "Par 74: 0.1046 Target: -0.0000\n",
      "Par 75: 0.1056 Target: -0.9995\n",
      "Par 76: 0.1049 Target: -0.9995\n",
      "Par 77: 0.1046 Target: -0.9995\n",
      "Par 78: 0.1046 Target: 1.0000\n",
      "Par 79: 0.1017 Target: 1.0000\n",
      "Par 80: 0.1034 Target: 1.0000\n",
      "Par 81: 0.1042 Target: 1.0000\n",
      "Par 82: 0.1070 Target: -0.9995\n",
      "Par 83: 0.1046 Target: -0.0000\n",
      "Par 84: 0.1050 Target: -0.9995\n",
      "Par 85: 0.1060 Target: -0.9995\n",
      "Par 86: 0.1045 Target: -0.9995\n",
      "Par 87: 0.1082 Target: -0.9995\n",
      "Par 88: 0.1054 Target: -0.9995\n",
      "Par 89: 0.1003 Target: -0.9995\n",
      "Par 90: 0.1039 Target: 1.0000\n",
      "Par 91: 0.1045 Target: -0.0000\n",
      "Par 92: 0.1045 Target: -0.0000\n",
      "Par 93: 0.1003 Target: 1.0000\n",
      "Par 94: 0.1082 Target: 1.0000\n",
      "Par 95: 0.1028 Target: 1.0000\n",
      "Par 96: 0.1045 Target: 1.0000\n",
      "Par 97: 0.1035 Target: 1.0000\n",
      "Par 98: 0.1045 Target: -0.0000\n",
      "Par 99: 0.1048 Target: -0.9995\n",
      "Par 100: 0.1045 Target: -0.0000\n",
      "Par 101: 0.1048 Target: 1.0000\n",
      "Par 102: 0.1045 Target: -0.0000\n",
      "Par 103: 0.1058 Target: -0.9995\n",
      "Par 104: 0.1045 Target: -0.0000\n",
      "Par 105: 0.1052 Target: -0.9995\n",
      "Par 106: 0.1045 Target: -0.0000\n",
      "Par 107: 0.1045 Target: -0.0000\n",
      "Par 108: 0.1048 Target: -0.9995\n",
      "Par 109: 0.1042 Target: 1.0000\n",
      "Par 110: 0.1042 Target: -0.9995\n",
      "Par 111: 0.1045 Target: -0.9995\n",
      "Par 112: 0.1030 Target: 1.0000\n",
      "Par 113: 0.1042 Target: 1.0000\n",
      "Par 114: 0.1037 Target: 1.0000\n",
      "Par 115: 0.1045 Target: -0.0000\n",
      "Par 116: 0.1045 Target: 1.0000\n",
      "Par 117: 0.1044 Target: -0.0000\n",
      "Par 118: 0.1044 Target: -0.0000\n",
      "Par 119: 0.1023 Target: -0.9995\n",
      "Par 120: 0.1044 Target: -0.0000\n",
      "Par 121: 0.1044 Target: -0.0000\n",
      "Par 122: 0.1063 Target: 1.0000\n",
      "Par 123: 0.1044 Target: -0.0000\n",
      "Par 124: 0.1076 Target: -0.9995\n",
      "Par 125: 0.1008 Target: 1.0000\n",
      "Par 126: 0.1044 Target: -0.0000\n",
      "Par 127: 0.1044 Target: -0.0000\n",
      "Par 128: 0.1037 Target: 1.0000\n",
      "Par 129: 0.1044 Target: -0.9995\n",
      "Par 130: 0.1044 Target: -0.0000\n",
      "Par 131: 0.1050 Target: -0.9995\n",
      "Par 132: 0.1044 Target: -0.0000\n",
      "Par 133: 0.1044 Target: 1.0000\n",
      "Par 134: 0.1044 Target: -0.0000\n",
      "Par 135: 0.1044 Target: -0.0000\n",
      "Par 136: 0.1043 Target: -0.0000\n",
      "Par 137: 0.1043 Target: -0.0000\n",
      "Par 138: 0.1043 Target: -0.0000\n",
      "Par 139: 0.1043 Target: -0.0000\n",
      "Par 140: 0.1043 Target: -0.0000\n",
      "Par 141: 0.1042 Target: -0.0000\n",
      "Par 142: 0.1042 Target: -0.0000\n",
      "Par 143: 0.1042 Target: -0.0000\n",
      "Par 144: 0.1042 Target: -0.9995\n",
      "Par 145: 0.1042 Target: 1.0000\n",
      "Par 146: 0.1039 Target: -0.0000\n",
      "Par 147: 0.1039 Target: -0.0000\n",
      "Par 148: 0.1060 Target: -0.9995\n",
      "Par 149: 0.1016 Target: 1.0000\n",
      "Par 150: 0.1036 Target: -0.0000\n"
     ]
    }
   ],
   "source": [
    "#  Converter DataLoader para iterador\n",
    "data_iter = iter(validation_dataloader)\n",
    "# Pegar o primeiro lote\n",
    "embeddings, lengths, targets = next(data_iter)\n",
    "print(\"validation_dataloader\",embeddings.shape,lengths.shape,targets.shape)\n",
    "\n",
    "# Ensure your model and inputs are in float16 if using AMP\n",
    "#model = model.half()\n",
    "#embeddings = embeddings.half()\n",
    "#targets = targets.half()\n",
    "\n",
    "model.to('cuda')\n",
    "embeddings = embeddings.to(torch.float32).to('cuda')\n",
    "lengths = lengths.to(torch.int64).to('cuda')\n",
    "targets = targets.to(torch.float32).to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Realizar a previsÃ£o\n",
    "with torch.no_grad():\n",
    "\toutput = model(embeddings, lengths)\n",
    "\n",
    "# Verificar os sinais de output e target usando os limites fornecidos\n",
    "output_sign = (output <= negative_threshold).float() - (output >= positive_threshold).float()\n",
    "target_sign = (targets <= negative_threshold).float() - (targets >= positive_threshold).float()\n",
    "\n",
    "# Calcular as correspondÃªncias\n",
    "matches = (output_sign == target_sign)\n",
    "\n",
    "# Calcular a precisÃ£o mÃ©dia\n",
    "accuracy = matches.float().mean()\n",
    "print(f\"AcurÃ¡cia: {accuracy:.4f}\")\n",
    "\n",
    "# Aplicar a inversÃ£o ao output e aos targets\n",
    "output_np = output.cpu().numpy().reshape(-1, 1)  # Converter para numpy e garantir formato bidimensional\n",
    "targets_np = targets.cpu().numpy().reshape(-1, 1)  # O mesmo para os targets\n",
    "\n",
    "# InversÃ£o\n",
    "output_inverse = scaler.inverse_transform(output_np)\n",
    "targets_inverse = scaler.inverse_transform(targets_np)\n",
    "\n",
    "# Imprimir os resultados da previsÃ£o junto com os valores target\n",
    "for i, (pred, target) in enumerate(zip(output_inverse, targets_inverse)):\n",
    "    print(f\"Par {i+1}: {inverse_signed_log_transform(pred.item()):.4f} Target: {inverse_signed_log_transform(target.item()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomHuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(CustomHuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "        self.huber_loss = nn.HuberLoss(delta=delta)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # Definir os limites para considerar positivo ou negativo\n",
    "        negative_threshold = -1.72\n",
    "        positive_threshold = 1.72\n",
    "\n",
    "        # Verificar os sinais de output e target usando os limites fornecidos\n",
    "        output_sign = (output < negative_threshold).float() - (output > positive_threshold).float()\n",
    "        target_sign = (target < negative_threshold).float() - (target > positive_threshold).float()\n",
    "\n",
    "        # Calcular a perda Huber normal\n",
    "        loss = self.huber_loss(output, target)\n",
    "\n",
    "        # Verificar se o sinal de output Ã© diferente de target\n",
    "        sign_diff = (output_sign != target_sign).float()\n",
    "\n",
    "        # Se os sinais forem diferentes, multiplicar a perda por 2\n",
    "        adjusted_loss = loss * (1 + sign_diff)  # Duas vezes a perda se os sinais forem diferentes\n",
    "\n",
    "        return adjusted_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 2.0 3.0 (ambos positivos): 0.5\n",
      "Loss -2.0 -3.0 (ambos negativos): 0.5\n",
      "Loss 2.0 -3.0 (output positivo, target negativo): 9.0\n",
      "Loss -2.0 3.0 (output negativo, target positivo): 9.0\n",
      "Loss 0.5 2.0 (output dentro do intervalo, target positivo): 2.0\n",
      "Loss -0.5 -2.0 (output dentro do intervalo, target negativo): 2.0\n",
      "Loss -0.5 0.5 (sinais diferentes dentro do intervalo): 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# FunÃ§Ã£o de teste da CustomHuberLoss\n",
    "def test_all_sign_cases():\n",
    "    # Instanciar a perda customizada\n",
    "    criterion = CustomHuberLoss(delta=1.0)\n",
    "\n",
    "    # Exemplo 1: Ambos positivos\n",
    "    output1 = torch.tensor([2.0])  # Positivo\n",
    "    target1 = torch.tensor([3.0])  # Positivo\n",
    "    loss1 = criterion(output1, target1)\n",
    "    print(f\"Loss 2.0 3.0 (ambos positivos): {loss1.item()}\")  # Esperado: perda normal\n",
    "\n",
    "    # Exemplo 2: Ambos negativos\n",
    "    output2 = torch.tensor([-2.0])  # Negativo\n",
    "    target2 = torch.tensor([-3.0])  # Negativo\n",
    "    loss2 = criterion(output2, target2)\n",
    "    print(f\"Loss -2.0 -3.0 (ambos negativos): {loss2.item()}\")  # Esperado: perda normal\n",
    "\n",
    "    # Exemplo 3: Output positivo, target negativo\n",
    "    output3 = torch.tensor([2.0])  # Positivo\n",
    "    target3 = torch.tensor([-3.0])  # Negativo\n",
    "    loss3 = criterion(output3, target3)\n",
    "    print(f\"Loss 2.0 -3.0 (output positivo, target negativo): {loss3.item()}\")  # Esperado: perda * 2\n",
    "\n",
    "    # Exemplo 4: Output negativo, target positivo\n",
    "    output4 = torch.tensor([-2.0])  # Negativo\n",
    "    target4 = torch.tensor([3.0])  # Positivo\n",
    "    loss4 = criterion(output4, target4)\n",
    "    print(f\"Loss -2.0 3.0 (output negativo, target positivo): {loss4.item()}\")  # Esperado: perda * 2\n",
    "\n",
    "    # Exemplo 5: Output dentro do intervalo, target positivo\n",
    "    output5 = torch.tensor([0.5])  # Dentro do intervalo\n",
    "    target5 = torch.tensor([2.0])  # Positivo\n",
    "    loss5 = criterion(output5, target5)\n",
    "    print(f\"Loss 0.5 2.0 (output dentro do intervalo, target positivo): {loss5.item()}\")  # Esperado: perda normal\n",
    "\n",
    "    # Exemplo 6: Output dentro do intervalo, target negativo\n",
    "    output6 = torch.tensor([-0.5])  # Dentro do intervalo\n",
    "    target6 = torch.tensor([-2.0])  # Negativo\n",
    "    loss6 = criterion(output6, target6)\n",
    "    print(f\"Loss -0.5 -2.0 (output dentro do intervalo, target negativo): {loss6.item()}\")  # Esperado: perda normal\n",
    "\n",
    "    # Exemplo 7: Ambos dentro do intervalo, mas sinais diferentes\n",
    "    output7 = torch.tensor([-0.5])  # Dentro do intervalo, negativo\n",
    "    target7 = torch.tensor([0.5])  # Dentro do intervalo, positivo\n",
    "    loss7 = criterion(output7, target7)\n",
    "    print(f\"Loss -0.5 0.5 (sinais diferentes dentro do intervalo): {loss7.item()}\")  # Esperado: perda * 2\n",
    "\n",
    "test_all_sign_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Inversa da DiferenÃ§a Absoluta\n",
      "CorrelaÃ§Ã£o de Pearson: 0.0912\n",
      "CorrelaÃ§Ã£o de Spearman: 0.0810\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import torch\n",
    "\n",
    "# Carregar o conjunto de dados de avaliaÃ§Ã£o (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Listas para armazenar as pontuaÃ§Ãµes reais e as previsÃµes do modelo\n",
    "true_scores = []\n",
    "pred_scores = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\tfor example in eval_dataset:\n",
    "\t\t# TokenizaÃ§Ã£o combinada\n",
    "\t\tencoding = embedding_generator.tokenizer(\n",
    "\t\t\t[example['sentence1'], example['sentence2']],\n",
    "\t\t\treturn_tensors=\"pt\",\n",
    "\t\t\tpadding=True,  # Padding dinÃ¢mico\n",
    "\t\t\ttruncation=True\n",
    "\t\t)\n",
    "\n",
    "\t\t# Converter para o dispositivo\n",
    "\t\tinput_ids1 = encoding['input_ids'][0]\n",
    "\t\tattention_mask1 = encoding['attention_mask'][0]\n",
    "\t\tinput_ids2 = encoding['input_ids'][1]\n",
    "\t\tattention_mask2 = encoding['attention_mask'][1]\n",
    "\n",
    "\t\t# Obter embeddings\n",
    "\t\tembeddings1 = embedding_generator.weights[input_ids1]\n",
    "\t\tembeddings2 = embedding_generator.weights[input_ids2]        \n",
    "\t\t\n",
    "\t\t# Concatenar as duas sequÃªncias no eixo 1\n",
    "\t\tembeddings = torch.stack([embeddings1, embeddings2]).float().unsqueeze(0).to('cuda')  # (batch_size, 2, seq_length, vector_size)\n",
    "\t\t\n",
    "\t\t# Calcular comprimentos\n",
    "\t\tlengths1 = attention_mask1.sum(dim=0)\n",
    "\t\tlengths2 = attention_mask2.sum(dim=0)\n",
    "\t\tlengths = torch.stack([lengths1, lengths2]).float().unsqueeze(0).to('cuda')  # (batch_size, 2)\n",
    "\n",
    "\t\t# Converter targets\n",
    "\t\tscore = torch.tensor(example['score'], dtype=torch.float16).unsqueeze(0).to('cuda')  # (batch_size,)\n",
    "\n",
    "\t\t# Obter a previsÃ£o do modelo\n",
    "\t\tprediction = model(embeddings, lengths)\n",
    "\t\t#output_np = prediction.cpu().numpy().reshape(-1, 1)\n",
    "\t\t\n",
    "\t\tpred_score = 1 / (1 + abs(prediction))\n",
    "\t\t#pred_score = 1 / (1 + abs(inverse_signed_log_transform(output_np.item())))\n",
    "\n",
    "\t\t# Armazenar as pontuaÃ§Ãµes\n",
    "\t\ttrue_scores.append(score.item())\n",
    "\t\tpred_scores.append(pred_score.item())\n",
    "\n",
    "# Calcular as mÃ©tricas de correlaÃ§Ã£o\n",
    "pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "\n",
    "print(\"Similaridade Inversa da DiferenÃ§a Absoluta\")\n",
    "print(f\"CorrelaÃ§Ã£o de Pearson: {pearson_corr:.4f}\")\n",
    "print(f\"CorrelaÃ§Ã£o de Spearman: {spearman_corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando exemplos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1500/1500 [00:03<00:00, 454.22it/s]\n",
      "Buscando o melhor k: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:14<00:00, 672.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Baseada em Exponencial\n",
      "Melhor valor de k: 0.001\n",
      "CorrelaÃ§Ã£o de Pearson: 0.0970\n",
      "CorrelaÃ§Ã£o de Spearman: 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from tqdm import tqdm  # Para acompanhar o progresso\n",
    "import numpy as np  # Certifique-se de importar o NumPy\n",
    "\n",
    "# Carregar o conjunto de dados de avaliaÃ§Ã£o (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Definir o intervalo de valores de k a serem testados\n",
    "k_values = np.arange(0.001, 100.0, 0.01)\n",
    "best_k = None\n",
    "best_pearson = -1  # InicializaÃ§Ã£o com um valor baixo\n",
    "best_spearman = -1\n",
    "\n",
    "# PrÃ©-computar todas as prediÃ§Ãµes para evitar recalcular mÃºltiplas vezes\n",
    "true_scores = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in tqdm(eval_dataset, desc=\"Processando exemplos\"):\n",
    "        # TokenizaÃ§Ã£o combinada\n",
    "        encoding = embedding_generator.tokenizer(\n",
    "            [example['sentence1'], example['sentence2']],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,  # Padding dinÃ¢mico\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        # Converter para o dispositivo\n",
    "        input_ids1 = encoding['input_ids'][0]\n",
    "        attention_mask1 = encoding['attention_mask'][0]\n",
    "        input_ids2 = encoding['input_ids'][1]\n",
    "        attention_mask2 = encoding['attention_mask'][1]\n",
    "\n",
    "        # Obter embeddings\n",
    "        embeddings1 = embedding_generator.weights[input_ids1]\n",
    "        embeddings2 = embedding_generator.weights[input_ids2]        \n",
    "        \n",
    "        # Concatenar as duas sequÃªncias no eixo 1\n",
    "        embeddings = torch.stack([embeddings1, embeddings2]).float().unsqueeze(0).to('cuda')  # (batch_size, 2, seq_length, vector_size)\n",
    "        \n",
    "        # Calcular comprimentos\n",
    "        lengths1 = attention_mask1.sum(dim=0)\n",
    "        lengths2 = attention_mask2.sum(dim=0)\n",
    "        lengths = torch.stack([lengths1, lengths2]).float().unsqueeze(0).to('cuda')  # (batch_size, 2)\n",
    "\n",
    "        # Converter targets\n",
    "        score = torch.tensor(example['score'], dtype=torch.float16).unsqueeze(0).to('cuda')  # (batch_size,)\n",
    "\n",
    "        # Obter a previsÃ£o do modelo\n",
    "        prediction = model(embeddings, lengths)\n",
    "        predictions.append(prediction.item())\n",
    "\n",
    "        # Armazenar as pontuaÃ§Ãµes reais como valores escalares\n",
    "        true_scores.append(score.item())\n",
    "\n",
    "true_scores = np.array(true_scores)  # Agora Ã© um array 1D\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Iterar sobre os valores de k para encontrar o melhor\n",
    "for k in tqdm(k_values, desc=\"Buscando o melhor k\"):\n",
    "    pred_scores = np.exp(-k * np.abs(predictions))\n",
    "    \n",
    "    pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "    spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "    \n",
    "    # Verificar se este k Ã© o melhor atÃ© agora\n",
    "    if pearson_corr > best_pearson:\n",
    "        best_pearson = pearson_corr\n",
    "        best_spearman = spearman_corr\n",
    "        best_k = k\n",
    "\n",
    "print(\"Similaridade Baseada em Exponencial\")\n",
    "print(f\"Melhor valor de k: {best_k}\")\n",
    "print(f\"CorrelaÃ§Ã£o de Pearson: {best_pearson:.4f}\")\n",
    "print(f\"CorrelaÃ§Ã£o de Spearman: {best_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datasets import load_dataset\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Verificar se CUDA estÃ¡ disponÃ­vel\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Carregar o modelo SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\").to(device)\n",
    "\n",
    "# Carregar o conjunto de dados de avaliaÃ§Ã£o (STS Benchmark)\n",
    "eval_dataset = load_dataset(\"sentence-transformers/stsb\", split=\"validation\")\n",
    "\n",
    "# Listas para armazenar as pontuaÃ§Ãµes reais e as previsÃµes do modelo\n",
    "true_scores = []\n",
    "pred_scores = []\n",
    "\n",
    "# Obter as sentenÃ§as e os escores do conjunto de dados\n",
    "sentences1 = eval_dataset['sentence1']\n",
    "sentences2 = eval_dataset['sentence2']\n",
    "scores = eval_dataset['score']\n",
    "\n",
    "# Processar uma frase por vez\n",
    "for i in range(len(eval_dataset)):\n",
    "    sentence1 = sentences1[i]\n",
    "    sentence2 = sentences2[i]\n",
    "    true_score = scores[i]\n",
    "\n",
    "    # Gerar embeddings para ambas as sentenÃ§as individualmente\n",
    "    embedding1 = model.encode(sentence1, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "    embedding2 = model.encode(sentence2, convert_to_tensor=True, device=device, show_progress_bar=False)\n",
    "\n",
    "    # Calcular a similaridade cosseno\n",
    "    cosine_score = util.cos_sim(embedding1, embedding2).item()\n",
    "\n",
    "    # Escalar a similaridade cosseno de [-1, 1] para [0, 1]\n",
    "    scaled_score = (cosine_score + 1) / 2\n",
    "\n",
    "    # Armazenar as pontuaÃ§Ãµes\n",
    "    true_scores.append(true_score)\n",
    "    pred_scores.append(scaled_score)\n",
    "\n",
    "# Calcular as mÃ©tricas de correlaÃ§Ã£o\n",
    "pearson_corr, _ = pearsonr(true_scores, pred_scores)\n",
    "spearman_corr, _ = spearmanr(true_scores, pred_scores)\n",
    "\n",
    "print(f\"CorrelaÃ§Ã£o de Pearson: {pearson_corr:.4f}\")\n",
    "print(f\"CorrelaÃ§Ã£o de Spearman: {spearman_corr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
